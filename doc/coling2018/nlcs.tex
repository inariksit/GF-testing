\documentclass[11pt]{article}
\usepackage{coling2018}
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
%\renewcommand\UrlFont{\color{blue}\rmfamily}
\usepackage{url}
\usepackage{color}
\usepackage{stackengine}
\usepackage[normalem]{ulem}
\input{syntaxhilight}

\def\t#1{\texttt{#1}}
\def\gf{\textsc{gf}}
\def\pgf{\textsc{pgf}}
\def\lfg{\textsc{lfg}}
\def\ccg{\textsc{ccg}}
\def\acg{\textsc{acg}}
\def\tag{\textsc{tag}}
\def\cfg{\textsc{cfg}}
\def\pmcfg{\textsc{pmcfg}}
\def\hpsg{\textsc{hpsg}}
\newcommand{\quality}[1]{${\tt AP_{#1}}$}
\newcommand{\kind}[1]{${\tt CN_{#1}}$}
\newcommand{\very}[1]{${\tt Very_{#1}}$}
\newcommand{\comment}{${\tt S}$}
\newcommand{\mod}[2]{${\tt Mod_{#1\times#2}}$}
\newcommand{\pred}[3]{${\tt Pred_{#1\times#2\times#3}}$}
\newcommand{\itemSpa}[2]{${\tt NP_{#1\times#2}}$}
\newcommand{\itemEng}[1]{${\tt NP_{#1}}$}
\newcommand{\todo}[1]{{\color{cyan}\textbf{[TODO: }#1\textbf{]}}}


\begin{document}
%
\title{Automatic test suite generation for PMCFG grammars}
%
\author{Inari Listenmaa and Koen Claessen \\
  Department of Computer Science and Engineering \\
  University of Gothenburg and Chalmers University of Technology \\
  Gothenburg, Sweden \\
  {\tt inari@chalmers.se, koen@chalmers.se} }

\maketitle              % typeset the header of the contribution
%
\begin{abstract}
We present a method for finding errors in formalized natural language grammars, by automatically and systematically generating test cases that are intended to be judged by a human oracle. The method works on a per-construction basis; given a construction from the grammar, it generates a finite but complete set of test sentences (typically tens or hundreds), where that construction is used in all possible ways. Our method is an alternative to using a corpus or a treebank, where no such completeness guarantees can be made. The method is language-independent and is implemented for the grammar formalism \pmcfg{}, but also works for weaker grammar formalisms. We evaluate the method on a number of different grammars for different natural languages, with sizes ranging from toy examples to real-world grammars.
\end{abstract}
%
%
%
\section{Introduction}

\todo{(Write a good first paragraph)
What is the essence of a language? 
Suppose we have a potentially infinite grammar, and we want to find a
minimal and representative set of sentences, along with their
analyses, to test the correctness of the grammar. Human judgment is
inavoidable, but we want to minimize the number of sentences the human
reads.}

To give an intuitive example: in English we need to test a reflexive
construct with three different 3rd person singular subjects, because
the object has to agree with the subject: ``he sees himself'', ``she
sees herself'' and ``it sees itself''. Without seeing all three
examples, we cannot be certain that the reflexive construction is
implemented correctly. In contrast, the general pattern of a transitive
verb with a non-reflexive object is enough to test with only one third
person subject: \emph{he, she, it}, or any singular noun or proper
name. The agreement only shows in the verb form, thus including both
``she sees a dog'' and ``John sees a dog'' in the test suite is redundant. 

Now, what is minimal and representative is highly language-dependent. 
For instance, Basque transitive verbs agree with both subject and
object, thus we need 6 $\times$ 6 examples just to cover all verb
forms. We are not interested in the morphology per se---there are
easier methods to test for that---but the correctness of the syntactic
function: does the function pick the correct verb form for the correct
combination of subject and object? For that purpose, it is enough to
test the syntactic construction ``transitive verb phrase'' with just a
single transitive verb.

Our concrete implementation is for a particular grammar formalism,
namely parallel multiple context-free grammars ({\sc pmcfg})
\cite{seki91pmcfg}, which is the core formalism used by the
Grammatical Framework (\gf) \cite{ranta2004gf}. However, the general
method works for any formalism that is at most as expressive as
\pmcfg{}, including formalisms such as Tree-Adjoining Grammar (\tag)
\cite{joshi1975tag} and several variants of Categorial Grammar, such
as Abstract Categorial Grammar
\todo{cite about the fragment of \acg{} that is MCFG} and 
Combinatorial Categorial Grammar (\ccg) \cite{steedman1988ccg}.

\todo{Emphasize the CS background of the work, in particular Feat,
  QuickCheck, and formal methods in general.}

\section{Grammatical Framework}
\label{sec:GF}

\todo{General \gf{} introduction.\\
1) Analysis and generation are all in the same
  grammar. \\ 2) GF as a formalism can be as syntactic or semantic as one wants.
}

\begin{figure}[h]
\centering

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{abstract }\DataTypeTok{Foods} \FunctionTok{=} \NormalTok{\{}
  \NormalTok{flags startcat }\FunctionTok{=} \DataTypeTok{S} \NormalTok{;}
  \NormalTok{cat}
    \DataTypeTok{S} \NormalTok{; }\DataTypeTok{NP} \NormalTok{; }\DataTypeTok{CN} \NormalTok{; }\DataTypeTok{AP} \NormalTok{;}
  \NormalTok{fun}
    \DataTypeTok{Pred}\OtherTok{ :} \DataTypeTok{NP} \OtherTok{->} \DataTypeTok{AP} \OtherTok{->} \DataTypeTok{S} \NormalTok{;                }\CommentTok{-- this wine is good}
    \DataTypeTok{This}\NormalTok{, }\DataTypeTok{That}\NormalTok{, }\DataTypeTok{These}\NormalTok{, }\DataTypeTok{Those}\OtherTok{ :} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{NP} \NormalTok{; }\CommentTok{-- this wine}
    \DataTypeTok{Mod}\OtherTok{ :} \DataTypeTok{AP} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;                }\CommentTok{-- Italian wine}
    \DataTypeTok{Wine}\NormalTok{, }\DataTypeTok{Cheese}\NormalTok{, }\DataTypeTok{Fish}\NormalTok{, }\DataTypeTok{Pizza}\OtherTok{ :} \DataTypeTok{CN} \NormalTok{;}
    \DataTypeTok{Warm}\NormalTok{, }\DataTypeTok{Good}\NormalTok{, }\DataTypeTok{Italian}\NormalTok{, }\DataTypeTok{Vegan}\OtherTok{ :} \DataTypeTok{AP} \NormalTok{;}
\end{Highlighting}
\end{Shaded}
  \caption{Abstract syntax of a GF grammar about food}
\label{fig:exampleGrammar}
\end{figure}

\subsection{Abstract syntax}

\subsection{Concrete syntax}

\begin{figure}[h]
\centering
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{concrete }\DataTypeTok{FoodsSpa} \KeywordTok{of} \DataTypeTok{Foods} \FunctionTok{=} \NormalTok{\{}
  \NormalTok{lincat}
    \DataTypeTok{S} \FunctionTok{=} \DataTypeTok{Str} \NormalTok{;}
    \DataTypeTok{NP} \FunctionTok{=} \NormalTok{\{ s }\OtherTok{:} \DataTypeTok{Str} \NormalTok{; n }\OtherTok{:} \DataTypeTok{Number} \NormalTok{; g }\OtherTok{:} \DataTypeTok{Gender} \NormalTok{\} ;}
    \DataTypeTok{CN} \FunctionTok{=} \NormalTok{\{ s }\OtherTok{:} \DataTypeTok{Number} \OtherTok{=>} \DataTypeTok{Str} \NormalTok{; g }\OtherTok{:} \DataTypeTok{Gender} \NormalTok{\} ;}
    \DataTypeTok{AP} \FunctionTok{=} \NormalTok{\{ s }\OtherTok{:} \DataTypeTok{Number} \OtherTok{=>} \DataTypeTok{Gender} \OtherTok{=>} \DataTypeTok{Str} \NormalTok{; p }\OtherTok{:} \DataTypeTok{Position} \NormalTok{\} ;}
  \NormalTok{lin}
    \DataTypeTok{Pred} \NormalTok{np ap }\FunctionTok{=} \NormalTok{np}\FunctionTok{.}\NormalTok{s }\FunctionTok{++} \NormalTok{copula }\FunctionTok{!} \NormalTok{np}\FunctionTok{.}\NormalTok{n }\FunctionTok{++} \NormalTok{ap.s }\FunctionTok{!} \NormalTok{np}\FunctionTok{.}\NormalTok{n }\FunctionTok{!} \NormalTok{np}\FunctionTok{.}\NormalTok{g ;}
    \DataTypeTok{This}\NormalTok{ cn} \FunctionTok{=} \NormalTok{mkNP }\DataTypeTok{Sg} \StringTok{"este"} \StringTok{"esta"} \NormalTok{cn ;}
    \DataTypeTok{These}\NormalTok{ cn} \FunctionTok{=} \NormalTok{mkNP }\DataTypeTok{Pl} \StringTok{"estos"} \StringTok{"estas"} \NormalTok{cn ;}
    \CommentTok{-- That, Those defined similarly}
    \DataTypeTok{Mod} \NormalTok{ap cn }\FunctionTok{=} \NormalTok{\{ s }\FunctionTok{=} \NormalTok{table \{n }\OtherTok{=>} \NormalTok{preOrPost ap}\FunctionTok{.}\NormalTok{p (ap }\FunctionTok{!} \NormalTok{n }\FunctionTok{!} \NormalTok{cn}\FunctionTok{.}\NormalTok{g) (cn}\FunctionTok{.}\NormalTok{s }\FunctionTok{!} \NormalTok{n) \} ;}
                  \NormalTok{g }\FunctionTok{=} \NormalTok{cn}\FunctionTok{.}\NormalTok{g \} ;}
    \CommentTok{--Wine, Cheese, \dots, Italian, Vegan defined as lexical items}
  \NormalTok{param}
    \DataTypeTok{Number} \FunctionTok{=} \DataTypeTok{Sg} \FunctionTok{|} \DataTypeTok{Pl} \NormalTok{;}
    \DataTypeTok{Gender} \FunctionTok{=} \DataTypeTok{Masc} \FunctionTok{|} \DataTypeTok{Fem} \NormalTok{;}
    \DataTypeTok{Position} \FunctionTok{=} \DataTypeTok{Pre} \FunctionTok{|} \DataTypeTok{Post} \NormalTok{;}
  \NormalTok{oper}
\NormalTok{    mkNP} \NormalTok{num mascDet femDet cn} \FunctionTok{=}
     \KeywordTok{let} \NormalTok{this }\FunctionTok{=} \KeywordTok{case} \NormalTok{cn}\FunctionTok{.}\NormalTok{g }\KeywordTok{of} \NormalTok{\{ }\DataTypeTok{Masc} \OtherTok{=>} \NormalTok{mascDet ; }\DataTypeTok{Fem} \OtherTok{=>} \NormalTok{femDet \} ;}
      \KeywordTok{in} \NormalTok{\{ s }\FunctionTok{=} \NormalTok{this }\FunctionTok{++} \NormalTok{cn}\FunctionTok{.}\NormalTok{s }\FunctionTok{!} \NormalTok{num} \NormalTok{;} \NormalTok{n }\FunctionTok{=} \NormalTok{num} \NormalTok{; g }\FunctionTok{=} \NormalTok{cn}\FunctionTok{.}\NormalTok{g \} ;}
    \NormalTok{copula }\FunctionTok{=} \NormalTok{table \{ }\DataTypeTok{Sg} \OtherTok{=>} \StringTok{"es"} \NormalTok{; }\DataTypeTok{Pl} \OtherTok{=>} \StringTok{"son"} \NormalTok{\} ;}
    \NormalTok{preOrPost p x y }\FunctionTok{=} \KeywordTok{case} \NormalTok{p }\KeywordTok{of} \NormalTok{\{ }\DataTypeTok{Pre} \OtherTok{=>} \NormalTok{x }\FunctionTok{++} \NormalTok{y ; }\DataTypeTok{Post} \OtherTok{=>} \NormalTok{y }\FunctionTok{++} \NormalTok{x \} ;}
\end{Highlighting}
\end{Shaded}
  \caption{Spanish concrete syntax of a GF grammar about food}
\label{fig:spanish}

\end{figure}

Figure~\ref{fig:exampleGrammar} shows the abstract syntax of a small
example grammar in GF, slightly modified from
\cite{ranta2011gfbook}. Figure~\ref{fig:spanish} shows a Spanish concrete
syntax. We refer to this grammar throughout sections~\ref{sec:GF}--\ref{sec:testing}. 

\t{CN}, `common noun', can be modified by adjectives or adverbs, but
it hasn't yet been quantified into a \t{NP}. 


\section{PMCFG}
\label{sec:PMCFG}

\gf{} grammars are compiled into parallel multiple context-free
grammars (\pmcfg), which are processed by our tool. Here we explain
three key features that are important for the test suite generation.

\subsection{Concrete categories}

For each category in the original grammar, the \gf{} compiler
introduces a new category in the \pmcfg{} for each combination of
inherent parameters.  
These categories can be linearized to strings or vectors of
strings. The start category (\t{S} in the Foods grammar) is in
general a single string, but intermediate categories may have to keep
several options open. 

Consider the categories \t{NP}, \t{CN} and \t{AP} in the
Spanish concrete syntax. Firstly, \t{NP} has inherent number
and gender, so it compiles into four concrete categories:
\itemSpa{sg}{masc}, \itemSpa{sg}{fem}, \itemSpa{pl}{masc} and
\itemSpa{pl}{fem}, each of them containing one string. Secondly,
\t{CN} has an inherent gender and variable number, so it compiles into
two concrete categories: \kind{masc} and \kind{fem}, each of them a
vector of two strings (singular and plural). Finally, \t{AP} needs to
agree in number and gender with its head, but it has its position as
an inherent feature.  Thus \t{AP} compiles into two concrete
categories: \quality{pre} and \quality{post}, each of them a vector of
four strings.
% ({\stackanchor{\tt \small pl}{\tt \small sg}}
%  $\times$ {\stackanchor{\tt \small masc}{\tt \small fem}}).

\subsection{Concrete functions}
Just like categories, each syntactic function from the original
grammar turns into multiple syntactic functions into the
\pmcfg{}---one for each combination of parameters of its arguments.

\begin{itemize}
\item[--] \mod{pre}{fem~~} \t{:} \quality{pre~} $\rightarrow$ \kind{fem~} $\rightarrow$ \kind{fem}
\item[--]  \mod{post}{fem~} \t{:} \quality{post} $\rightarrow$ \kind{fem~} $\rightarrow$ \kind{fem}
\item[--]  \mod{pre}{masc~~}\t{:} \quality{pre~} $\rightarrow$ \kind{masc} $\rightarrow$ \kind{masc}
\item[--] \mod{post}{masc} \t{:} \quality{post} $\rightarrow$ \kind{masc} $\rightarrow$ \kind{masc}
\end{itemize}


\subsection{Coercions}
\label{sec:Coercions}
As we have seen, \t{AP} in Spanish compiles into \quality{pre} and
\quality{post}. However, the difference of position is meaningful only when the
adjective is modifying the noun: ``la \emph{buena} pizza'' vs. ``la pizza
\emph{vegana}''. But when we use an adjective in a predicative position, both
classes of adjectives behave the same: ``la pizza es \emph{buena}''
and ``la pizza es \emph{vegana}''. As an optimization strategy, the
grammar creates a {\it coercion}: both \quality{pre} and \quality{post}
may be treated as \quality{*} when the distinction doesn't matter. 
Furthermore, the function \t{Pred : NP $\rightarrow$ AP $\rightarrow$ S} uses
the coerced category \quality{*} as its second argument, and thus
expands only into 4 variants, despite there being 8 combinations of
\t{NP}$\times$\t{AP}.

\begin{itemize}
\item[--] \pred{sg}{fem}{*~} \t{:} \itemSpa{sg}{fem~} $\rightarrow$ \quality{*} $\rightarrow$ \comment
\item[--]  \pred{pl}{fem}{*~} \t{:} \itemSpa{pl}{fem~} $\rightarrow$ \quality{*} $\rightarrow$ \comment
\item[--]  \pred{sg}{masc}{*} \t{:} \itemSpa{sg}{masc} $\rightarrow$ \quality{*} $\rightarrow$ \comment
\item[--] \pred{pl}{masc}{*} \t{:} \itemSpa{pl}{masc} $\rightarrow$ \quality{*} $\rightarrow$ \comment
\end{itemize}

\section{Generating the test suite}
\label{sec:testing}

We now have all building blocks for creating a representative and
minimal set of test cases.
In the previous section, we saw how a single abstract category
compiles into multiple concrete categories, depending on the
combinations of parameters. This compilation step can dramatically
increase the number of categories of the grammar, but it also removes
the need for dealing with these parameters explicitly when we generate
test cases. 

We use one syntactic function as the base for one set of test
cases. For lexical categories, it also makes sense to test the whole
category, i.e. generate all trees that show that \t{AP} is defined and
handled correctly in the functions. However, we only explain in detail
the method with one syntactic function as a base.

We assume that all test cases are trees with the same start
(top-level) category, such as \t{S} in our example grammar. The
requirement is that the start category is linearized as one string only. 

\subsection{Enumerate functions} As we explained before, each syntactic
function turns into multiple versions, one for each combination of
parameters of its arguments. We test each of these versions
seperately. Each concrete syntactic function may produce one or several trees.

In order to construct trees that use the syntactic function, we need
to supply it with \emph{arguments}, as well as put the resulting tree
into a \emph{context} that produces a tree in the correct start
category.

\subsection{Enumerate arguments} Some syntactic functions are
simply a single lexical item (for example the word \emph{good}); in
this case just the tree \t{Good} is our answer.
If we choose a function with arguments, such as \t{Pred}, then we have
to supply it with argument trees. Each argument needs to be a
tree belonging to the right category (in the example, \t{NP} and
\t{AP}, respectively). 

When we test a function, we want to see whether or not it uses the
right information from its arguments, in the right way. The
information that a syntactic function uses is any of the strings that
come from linearizing its arguments. In order to be able to see which
string in the result comes from which field from which argument, we
want to generate test cases that only contain unique strings.
For example, \t{Good} `bueno/buena/buenos/buenas' is a
better argument than \t{Warm} `caliente/caliente/calientes/calientes',
because the latter is invariable for gender.

It is often possible to generate one combination of arguments where
all strings in the linearizations are different. However, it is not
always possible to do this, which is why we in general aim to generate
a set of combinations of arguments, where for each pair of strings
from the arguments, there is always one test case where those strings
are different. In this way, if the syntactic function contains a
mistake, there is always one test case that reveals it.

\paragraph{Example: Test cases using \t{Mod}} Let us test the function
\t{Mod : AP $\rightarrow$ CN $\rightarrow$ CN} in the Spanish
concrete syntax.
Firstly, we need a minimal and representative set of arguments:
one premodifier and one postmodifier \t{AP} (\t{Good} and
\t{Vegan}), as well as one feminine and one masculine
\t{CN} (\t{Pizza} and \t{Wine}). Now, our full set of test cases are
\t{Mod} applied to the cross product of \{\stackanchor{\tt \small
  Good}{\tt \small Vegan}\} $\times$ \{\stackanchor{\tt \small
  Pizza}{\tt \small Wine}\}, as seen in Table~\ref{tab:adjAttr}.

\begin{table}[h]
\centering
\begin{tabular}{| l | l |}
\hline
\t{Mod Good Pizza}   & \t{Mod Good Wine} \\ 
\textsc{(sg)} buena pizza             & \textsc{(sg)} buen vino \\
\textsc{(pl)} buenas pizzas           & \textsc{(pl)} buenos vinos \\ \hline

\t{Mod Vegan Pizza}   & \t{Mod Vegan Wine} \\ 
\textsc{(sg)} pizza vegana            & \textsc{(sg)} vino vegano \\
\textsc{(pl)} pizzas veganas          & \textsc{(pl)} vinos veganos \\ \hline
\end{tabular}
\caption{Agreement and placement of adjectives in attributive position}
\label{tab:adjAttr}
\end{table}

\subsection{Enumerate contexts} The third and last enumeration we
perform when generating test cases is to generate all possible
\emph{uses} of a function. After we provide a function with arguments,
we need to put the result into a context, so that we can generate a
single string from the result (a sentence). We do this for all trees
we have generated so far. 

The important thing here is that the generated set of contexts shows
all the possible different ways the tree can be used. For example, for
a test tree with an inflection table of 4 forms, we would generate 4 different sentences in which each of the 4 inflections is used.

By \emph{context}, we mean a tree in the start category \t{S}, with a 
\emph{hole} of type \t{CN}. 
Since \t{CN} is variable for number, we need two contexts: 
one that picks out the singular form and other that picks out
the plural form. 
This suggests that we should apply two different
\t{CN $\rightarrow$ NP} functions, for instance \t{This} and \t{These}, and
give their results to the \t{Pred} function, which constructs a \t{S}.
In contrast, the second argument to \t{Pred} doesn't make a difference
in what form we pick out of the \t{CN}---we just want to pick
something that has maximally different forms, so the program is sure
not to pick \t{Warm}, which is invariable for gender. By random
selection, let us pick \t{Italian}.
The final contexts are \verb|Pred (This _) Italian| and \verb|Pred (These _) Italian|.
We insert the 4 test cases from Figure~\ref{tab:adjAttr} into the
holes, and get 8 trees in total: 

\begin{table}
\centering
\begin{tabular}{| l | l |}
\hline
\t{Pred (This (Mod Good Pizza)) Italian} & \t{Pred (This (Mod Good Wine))
                                        Italian} \\ 
esta buena pizza es italiana          & este buen vino es italiano \\ \hline
\t{Pred (These (Mod Good Pizza)) Italian} & \t{Pred (These (Mod Good Wine))
                                        Italian} \\ 
estas buenas pizzas son italianas          & estos buenos vinos son italianos \\ \hline
\t{Pred (This (Mod Vegan Pizza)) Italian} & \t{Pred (This (Mod Vegan Wine))
                                        Italian} \\ 
esta pizza vegana es italiana          & este vino vegano es italiano \\ \hline
\t{Pred (These (Mod Vegan Pizza)) Italian} & \t{Pred (These (Mod Vegan Wine))
                                        Italian} \\ 
estas pizzas veganas son italianas          & estos vinos veganos son italianos \\ \hline
\end{tabular}
\caption{Complete test cases to test \t{Mod}}
\label{tab:testCases}
\end{table}

So, what we want to compute is, given the result category T of the syntactic function, and the start category S of the grammar, a minimal set of contexts in the start category S with hole of type T, such that any string appearing in the linearization of T also appears somewhere in the linearization of S. We compute this by setting up a system of equations for each category C in the grammar: for each C, we define all the relevant contexts with hole type C in terms of all the relevant contexts with hole type C' for other categories C' that use C. So, the answer for each category is expressed in terms of the answer for other categories. In general, this system of equations is \emph{recursive}, and we use a fixpoint iteration to compute the smallest solution.

\subsection{Pruning the trees within one set of test cases} 
On the scope of our tiny example grammar, this pruning method is
easiest to illustrate when we test a category instead of a function;
however, in bigger grammars, the need arises when testing functions as
well. 
In order to test the category \t{AP}, we need in total 12 example sentences:
\begin{itemize}
\item[--] 4 test cases for a premodifier \t{AP} as modifier;
\item[--] 4 test cases for a postmodifier \t{AP} as modifier;
\item[--] 4 test cases for \emph{any} \t{AP} as predicative.
\end{itemize}
These categories correspond to the concrete categories \kind{pre},
\kind{post} and the coercion \kind{*} (as explained in
Section~\ref{sec:Coercions}). Instead of generating redundant test
cases for the predicative, we use the coercions in the grammar to
detect when something is redundant.

\subsection{Pruning the trees to test the whole grammar}
So far we have completely ignored that one tree can showcase more
than one function. In fact, the 8 test sentences created for \t{Mod}
happen to also test \t{Pred} exhaustively.
Let us recap the steps we took to create them for \t{Mod}:
enumerating arguments brought us \t{Good}, \t{Vegan}, \t{Pizza} and
\t{Wine}, and enumerating contexts brought us \t{This} and
\t{These}. Had we been creating test cases for \t{Pred}, we would've
gotten \t{This} and \t{These} at the stage of enumerating arguments,
and then there would've been no need for contexts, because \t{Pred}
already creates the start category \t{S}.

There is a simple way to detect the redundancy: make the generation of
arguments completely deterministic, e.g. always choose the function
that is alphabetically first. The downside is that we get a lot of
redundancy, in the style of ``the good pizza is good''. The problem
gets more severe when testing functions with more arguments: ``the
pizza gives the pizza the pizza'' is not only boring but confusing.
However, if we want to generate sentences for the whole grammar at one 
go, we can split the generation in two stages: first stage is
deterministic, where every feminine noun is \t{Pizza}, and we can 
eliminate redundancies by just eliminating copies of the same
tree. Then, when we have a set of unique trees, we can substitute
individual words in them with other words in the same concrete
category.
%  ``the house gives the pizza the fountain'' has the same
% testing property as the version with pizza in every role, but at least
% it is easier to keep track who does what, and compare the translations
% of the same tree. 

It would be ideal to generate sentences that make sense,
such as ``the waitress gives the girl the pizza''. If the grammar is
purely syntactic, we would need external tools to ensure semantic
coherence, but if the grammatical categories already include semantic
distinctions, e.g. limiting the subject and indirect object of
\emph{give} into humans, that naturally restricts the generated test suite.

\section{Use cases}

Here is a typical use for the tool. 
Let us take the GF resource grammar \cite{ranta2009rgl} for Spanish, and
pick the function \t{AdvCN : Adv $\rightarrow$ CN $\rightarrow$ CN}, modifies a \t{CN} with
an adverb.
The tool generates test cases in the way described previously,
which include the following (slightly simplified) trees: 
\begin{itemize}
\item[--] \t{AdvCN (PrepNP next\_to (DetNP your)) hill} `hill next to
yours'
\item[--] \t{AdvCN (PrepNP next\_to (DetNP your)) house} `house next
to yours'
\end{itemize}
In Spanish, the words \emph{hill} and \emph{house} have different
genders, and the word \emph{yours} has to agree in gender 
with the antecedent: \emph{(la) casa al lado de la tuya} and \emph{(el)
  cerro al lado del tuyo}. The test cases reveal a bug, where \t{DetNP your} 
picks a gender too soon, say always masculine, instead of leaving it
open in an inflection table. We implement a fix by adding gender as a
parameter to the \t{Adv} type, and have \t{AdvCN} choose the correct
form based on the gender of the \t{CN}.

After implementing the fix, we run a second test case generation: this
time, not meant for human eyes, but just to compare the old and new
versions of the grammar. We want to make sure that our changes 
have not caused new bugs in other functions. The simplest strategy is
to generate test cases for \emph{all} functions in both grammars, and
only show those outputs that differ between the grammars. After our
fixes, we get the following differences: 

\begin{itemize}
\item \t{DetCN the (AdvCN (PrepNP next\_to (DetNP your)) house)}
  \begin{itemize}
   \item \emph{\sout{la casa al lado {\bf  del tuyo}}}
   \item \emph{la casa al lado {\bf  de la tuya}}
  \end{itemize}
\item \t{DetCN the (AdvCN (PrepNP without (DetNP this)) house)}
  \begin{itemize}
   \item \emph{\sout{la casa sin {\bf  esto}}}
   \item \emph{la casa sin {\bf esta}}
  \end{itemize}
\end{itemize}

\noindent We notice a side effect that we may not have thought of: the
gender is retained in all adverbs made of NPs made of determiners, so
now it has become impossible to say ``the hill without \emph{that}'' and
pointing to a house. So we do another round of modifications, compute
the difference (to the original grammar or to the intermediate), and
see if something else broke.

\section{Evaluation}

In order to evaluate our method, we generate test cases for two
grammars of different sizes, using three languages from different
language families: Dutch, Estonian and Basque. Dutch, an Indo-European
language, has fairly simple nominal and verbal morphology, but the
rules for handling word order, prefixes and particles in verb phrases
are somewhat intricate. Estonian and Basque both have rich morphology,
each featuring 14 nominal cases, but Basque verb morphology is much
more complex, with agreement in subject, object and indirect
object. Contrary to our expectations, we found Dutch and Estonian
behaving similarly to each other and Basque significantly worse, both
in execution time and number of examples generated. 

Table~\ref{results} shows the number of generated trees for 
in total for all syntactic functions in the three grammars. 
As stated earlier, we do not consider generating test cases for all
functions an optimal way of testing a whole resource grammar from scratch;
this gives merely a baseline reduction from all possible trees up to a
reasonable depth. We introduce the grammars and comment on the results
in the following sections.

\begin{table}[h]
\centering
\begin{tabular}{|lll|ll|ll|ll|}
\hline
\multicolumn{3}{|r}{Concrete $\rightarrow$}              &
                                                                   \multicolumn{2}{|c}{\bf Dutch} & \multicolumn{2}{|c}{\bf Basque} & \multicolumn{2}{|c|}{\bf Estonian} \\
$\downarrow$ Abstract  & \#funs+lex & \#trees  &
                                                                 \#total & \#uniq & \#total & \#uniq  & \#total  & \#uniq \\ \hline
{\bf Phrasebook}       & 130+160         & \textgreater{}480,000       & 2006  & 1892   & 2808    & 2650    & 1513     & 1314   \\ \hline
{\bf Resource gr.} & 217+446         & \textgreater{}500 billion   & 59,316 & 51,145  & 278,092  & 216,058  & 60,600    & 38,517   \\ \hline
\end{tabular}
\caption{Test cases for all functions in two grammars}
\label{results}
\end{table}

\subsection{Grammars}

The first grammar is Phrasebook \cite{ranta2010phrasebook}, a mid-size
application grammar with 42 categories such as \t{Person, Currency,
  Price} and \t{Nationality}, 160-word lexicon and 130 functions with
arguments. The trees in the Phrasebook are more semantic than the
trees we have seen so far: for example, the abstract tree for the sentence ``how far is the bar?'' in the Phrasebook is {\tt PQuestion (HowFar (ThePlace Bar))}, in contrast to the resource grammar tree
{\tt \small UseQCl (TTAnt TPres ASimul) PPos (QuestIComp
  (CompIAdv (AdvIAdv how\_IAdv (PositAdvAdj far\_A))) 
  (DetCN (DetQuant DefArt NumSg) (UseN bar\_N)))} for the same
sentence. Limiting up to depth 3, the Phrasebook grammar produces over
480,000 trees\footnote{Application grammars are usually
much more compact than resource grammars, hence depth 3 covers already
a lot of relevant trees.}.

The second grammar is a restricted version of the \gf{} resource
grammar \cite{ranta2009rgl}, with 84 categories, 217 syntactic
functions and 446 words in the lexicon. Since all the languages did
not have a complete implementation, we simply took the subset of functions that was
common, and removed manually a couple of rare constructions and words
that are potentially distracting. However, we should not limit the
lexicon too much, because we may miss important distinctions  in some
languages---to give a hypothetical example, some grammar may have a
bug that shows up only in animate nouns which end in a consonant. This
subset of the resource grammar produces hundreds of billions of trees
up to depth 5.
\subsection{Results}

\paragraph{Execution time} We ran all the experiments on a MacBook Air with 1,7 GHz processor and 8 GB RAM.
For the smaller grammars, all languages took just
seconds to run. For the resource grammar, Dutch and Estonian finished in
3--4 minutes.
However, the Basque resource grammar is noticeably more complex, and
creating test trees for all functions took several hours. We ran the
experiment in smaller batches over two days, and noticed a lot of
variance: functions that handle e.g. noun phrases, adjectives and
adverbs ran in a few minutes, but a function involving verb phrases
could take an hour just by itself. 

\paragraph{Generated trees} 

We believe this has both language typological and grammar engineering
implications---there is no way to implement Basque in a way that
results in as few example sentences as English, but other resource
grammarians have reported significant differences in complexity
between implementations---\cite{enache2010} reports a
200-time reduction in the number of concrete rules after changing the
implementation of clitics in verb phrases.

\paragraph{Finding bugs} 
We read through the test sentences of the small grammar in all the
three languages. 
For Dutch we had a native speaker; for Estonian an intermediate non-native,
and for Basque, a beginner. None of the three grammars had been tested
systematically before---\cite{listenmaa_kaljurand2014} report testing
the morphological paradigms extensively against existing resources,
and syntactic functions with a treebank of 425 trees.

We have been developing the tool by testing it on the Dutch resource
grammar, and during 4 months, we have committed 16 bugfixes in the
\gf{} main repository. (In the name of honesty, a few of the bugs were
caused by our earlier ``fixes''---that was before we had implemented
the comparison against an older version of the grammar!) 

The Basque resource grammar is still a work in progress, and the
test sentences showed serious problems in morphology.
We thought it premature to get a fluent speaker to evaluate the grammar,
because the errors in morphology would probably make it
difficult to assess syntax separately. We think that the best course
of action is to evaluate the morphological paradigms against existing
resources, fix the implementation, and then concentrate on syntax.
The Phrasebook was implemented using the resource grammar, so the
same problems apply.

We read through the first 500 sentences from Estonian Phrasebook,
which took around 20 minutes. We found 3 errors in the inflection of
individual words (they did not come from the resource lexicon, which
was tested, but were implemented separately in the grammar); one error
of type ``Spaniard restaurant'', and one suggestion for a more idiomatic
construction. As expected, Phrasebook sentences were easier to read,
and made more sense semantically than sentences from the resource
grammar.




\bibliographystyle{acl}
\bibliography{bibliography}

\end{document}
