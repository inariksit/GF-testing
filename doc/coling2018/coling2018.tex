%
% File coling2018.tex
%
% Contact: zhu2048@gmail.com & liuzy@tsinghua.edu.cn
%% Based on the style files for COLING-2016, which were, in turn,
%% Based on the style files for COLING-2014, which were, in turn,
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{coling2018}
\usepackage{times}
\usepackage{url}
\usepackage{color}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{stackengine}
\input{syntaxhilight} % suspicious

\def\t#1{\texttt{#1}}
\def\gf{\textsc{gf}}
\def\lfg{\textsc{lfg}}
\def\ccg{\textsc{ccg}}
\def\tag{\textsc{tag}}
\def\pmcfg{\textsc{pmcfg}}
\def\hpsg{\textsc{hpsg}}
\newcommand{\tts}[1]{{\tt #1}}
%\newcommand{\tts}[1]{{\tt \small #1}}
\newcommand{\todo}[1]{{\color{cyan}\textbf{[TODO: }#1\textbf{]}}}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Automatic systematic test case generation for producing reliable grammars}

\author{Inari Listenmaa and Koen Claessen \\
  Department of Computer Science and Engineering \\
  University of Gothenburg and Chalmers University of Technology \\
  Gothenburg, Sweden \\
  {\tt inari@chalmers.se, koen@chalmers.se} }
%\\\And
%  Koen Claessen \\
%  Department of Computer Science and Engineering \\
%  Chalmers University of Technology \\
%  Gothenburg, Sweden \\
 % {\tt koen@chalmers.se} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
We present a method for finding errors in formalized natural language grammars, by automatically and systematically generating test cases that are intended to be judged by a human oracle. The method works on a per-construction basis; given a construction from the grammar, it generates a finite but complete set of test sentences (typically tens or hundreds), where that construction is used in all possible ways. We contrast our method against using a corpus or a treebank, where no such completeness guarantees can be made. Our method is language-independent and is implemented for the grammar formalism PMCFG, but also works for weaker grammar formalisms.
\end{abstract}

\section{Introduction}

Grammar engineering has a lot in common with software
engineering. Analogous to a program specification, we use
descriptive grammar books; in place of unit tests, we have gold
standard corpora and test cases for manual inspection.
And just like any software, our grammars still contain bugs:
grammatical sentences that are rejected, ungrammatical
sentences that are parsed, or grammatical sentences that get the wrong
parse.

There are several ways to test grammars that do not involve human
labour. Morphology and lexicon can be compared against existing resources, or
if there are none, a large corpus of any text should give indications
whether the word forms are correct. The same corpus can be used to
test the coverage of the grammar: how many sentences are successfully parsed.
However, often we want information beyond numbers: do the rules we
wrote for relative clauses correctly accept all relative clauses and
nothing else? In other words, we are interested in the strong
generative capacity \todo{chomsky1963} of the grammar, i.e. combinations
of a string and its structural description.

Here is an example of a typical situation we want to improve. Suppose a
grammarian implements relative clauses, and then comes up with a test
suite of sentences with their analyses. The next grammarian implements
relative clauses for another language, and adapts the test set to the
new language. Every time someone touches relative clauses 
in any language, the test suite will be rerun and verified by
someone who knows the language, or compared to the original gold standard, 
if there is one. This scheme can fail for various reasons: 

% When implementing some feature, such as 
% relative clauses, the grammarian comes up with a test suite of 
% sentences that include relative clauses, and stores in the form of 
% abstract syntax trees. In principle, a test suite created for one 
% language can easily be reused for another, because the ASTs are 
% identical.

\begin{itemize}
\item The original list is not exhaustive: for instance, it tests only
``X, who loves me'' but not ``X, whom I love''. 
\item The original list is exhaustive in one language, but not in all:
for instance, it started in English and only included one noun, but in
French it would need at least one masculine and one feminine noun. 
\item The list is overly long, with redundant test cases, and human
testers are not motivated to read through. 
\item A grammarian makes a change somewhere else in the grammar, and
does not realise that it affects relative clauses, and thus does not
rerun the appropriate test suite. 
\end{itemize}

We present a method that addresses these problems, by designing a tool that can automatically generate test cases, given a grammar and a syntactic function that we want to test. Our tool improves on the four weak points in the following way:

\begin{itemize}
\item The set of test cases consists of the syntactic function, applied
  to all relevant arguments and the result is placed in all relevant
  contexts (``relevant'' is defined in
  Section~\ref{sec:details}).
  %Given a grammar and a category, the
  %program can extract all functions that produce or use the given category. 
\item The tests cases are automatically generated for each different
  language. If there is a parameter of gender or noun class in the
  grammar, then the program is guaranteed to choose an example of each
  of them, when it matters.
\item When some feature doesn't matter, the test cases are pruned: for
  example, in English we need to test a reflexive construct with three
  different 3rd person singular subjects, because the object has to
  agree with the subject: ``he sees himself'', ``she sees herself''
  and ``it sees itself''. With a non-reflexive object, it is
  enough to test with only one of \emph{he, she, it}, or any singular
  noun or proper name, because the agreement only shows in the verb
  form, thus generating both ``she sees a dog'' and ``John sees a
  dog'' is redundant.
\item The grammar is a collection of grammatical categories, syntactic
  functions and a lexicon, and everything is interconnected. By
  changing e.g. the category of prepositions, the changes are
  propagated to several functions, e.g. for building adjuncts (``in
  the house'') and complements (``believe in something''). This is
  all part of the grammar, and the chain of effects can be
  automatically traced. 
\end{itemize}

Our concrete implementation is for a particular grammar formalism, namely parallel multiple context-free grammars ({\sc pmcfg}) \cite{seki91pmcfg}, which is the core formalism used by Grammatical Framework (GF \cite{ranta2004gf}). However, the method works for any formalism that is at most as expressive as PMCFG, including formalisms such as Tree-Adjoining Grammar (\tag) \cite{joshi1975tag} and Combinatorial Categorial Grammar (\ccg) \cite{steedman1988ccg}.

\section{Grammatical Framework}
Grammatical Framework (\gf) \cite{ranta2004gf} 
is a framework for building multilingual grammar applications. Its main
components are a functional programming language for writing grammars
and a resource library \cite{ranta2009rgl}, which, as of March 2018,
contains the linguistic details of 40 natural languages. \gf{} has
been used in several projects \todo{Ask Aarne how to boast about \gf} and
is super cool.

A \gf{} grammar consists of an \emph{abstract syntax}, which is a set
of grammatical categories and functions between them, and one or more
\emph{concrete syntaxes}, which describe how the abstract functions
and categories are linearised, i.e. turned into surface strings. The
resulting grammar describes a mapping between concrete language
strings and their corresponding abstract trees. This mapping is
bidirectional---strings can be \emph{parsed} to trees, and trees
\emph{linearised} to strings. As an abstract syntax can have multiple
corresponding concrete syntaxes, the respective languages can be
automatically \emph{translated} from one to the other by first parsing
a string into a tree and then linearising the obtained tree into a new
string. 

% \todo{this is stolen from Janna's paper 2006--reformulate:}
% \begin{quote} { \em [RGL] Abstract syntax declares universal principles, while language-specific
% parameters are set in concrete syntax. We are not trying to answer the
% general question what constitutes universal grammar and what beyond
% universal grammar differentiates languages from one another. We look
% at GF parallel resource grammars as a way to simplify multilingual
% applications. \dots
% According to the ``division of labor'' principle, resource grammars
% comprise the necessary linguistic knowledge allowing application
% grammarians to concentrate on domain semantics.}
% \end{quote}



%Concrete problems: the kind of bugs we set out to find
%* Empty categories
%* Empty fields
%* Eliminated arguments

%Pick ~3 bugs: 
%what tree was generated? why? likelihood of finding this bug without our method.

%Results


\begin{figure}[h]
  \centering

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{abstract }\DataTypeTok{NounPhrases} \FunctionTok{=} \NormalTok{\{}
  \NormalTok{flags startcat }\FunctionTok{=} \DataTypeTok{NP} \NormalTok{;}
  \KeywordTok{cat}
    \DataTypeTok{NP} \NormalTok{; }\DataTypeTok{Adv} \NormalTok{;                   }\CommentTok{-- Non-terminal categories}
    \DataTypeTok{CN} \NormalTok{; }\DataTypeTok{Det} \NormalTok{; }\DataTypeTok{Adj} \NormalTok{; }\DataTypeTok{Prep} \NormalTok{;      }\CommentTok{-- Terminal (lexical) categories}
  \KeywordTok{fun}
    \NormalTok{DetNP} \FunctionTok{:} \DataTypeTok{Det} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;          }\CommentTok{-- e.g. "this"; "yours"}
    \NormalTok{DetCN} \FunctionTok{:} \DataTypeTok{Det} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;    }\CommentTok{-- e.g. "this house"}
    \NormalTok{PrepNP} \FunctionTok{:} \DataTypeTok{Prep} \OtherTok{->} \DataTypeTok{NP} \OtherTok{->} \DataTypeTok{Adv} \NormalTok{; }\CommentTok{-- e.g. "without the house"}
    \NormalTok{AdjCN} \FunctionTok{:} \DataTypeTok{Adj} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;    }\CommentTok{-- e.g. "small house"}
    \NormalTok{AdvCN} \FunctionTok{:} \DataTypeTok{Adv} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;    }\CommentTok{-- e.g. "house on a hill"}

    \NormalTok{a, the, this, these, your }\FunctionTok{:} \DataTypeTok{Det} \NormalTok{;}
    \NormalTok{good, small, blue, ready }\FunctionTok{:} \DataTypeTok{Adj} \NormalTok{;}
    \NormalTok{house, hill }\FunctionTok{:} \DataTypeTok{CN} \NormalTok{;}
    \NormalTok{in, on, with, without }\FunctionTok{:} \DataTypeTok{Prep} \NormalTok{; }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

% \begin{verbatim}
% abstract NounPhrases = {
%   flags startcat = NP ;
%   cat
%     NP ; Adv ;                   -- Non-terminal categories
%     CN ; Det ; Adj ; Prep ;      -- Terminal (lexical) categories
%   fun
%     DetNP : Det -> NP ;          -- e.g. "this"; "yours"
%     DetCN : Det -> CN -> NP ;    -- e.g. "this house"
%     PrepNP : Prep -> NP -> Adv ; -- e.g. "without the house"
%     AdjCN : Adj -> CN -> CN ;    -- e.g. "small house"
%     AdvCN : Adv -> CN -> CN ;    -- e.g. "house on a hill"

%     a, the, this, these, your : Det ;
%     good, small, blue, ready : Adj ;
%     house, hill, cake : CN ;
%     in, on, with, without : Prep ; 
% }
% \end{verbatim}
  \caption{GF grammar for noun phrases}
\label{fig:exampleGrammar}
\end{figure}

Figure~\ref{fig:exampleGrammar} shows a small example of a GF
grammar. The grammar generates noun phrases for a lexicon of 15
words (\emph{a, the, \dots, without}) in four lexical categories,
and five functions to construct phrases. \t{CN} stands for common
noun, and it can be modified by arbitrarily many adjectives (\t{Adj}),
e.g. \emph{small blue house} is an English linearisation of the
abstract syntax tree \t{AdjCN small (AdjCN blue house)}. A \t{CN} is
quantified into a noun phrase (\t{NP}) by adding a determiner
(\t{Det}), e.g. \emph{the small house} corresponds to tree \t{DetCN the (AdjCN small
  house)}. Alternatively, a \t{Det} can also become an independent
noun phrase (as in, \emph{(I like) this} instead of \emph{(I like) this
  house}) using the constructor \t{DetNP}. Finally, we can form an
adverb (\t{Adv}) by combining a preposition (\t{Prep}) with an \t{NP},
and those adverbs can modify yet another \t{CN}. 
We refer to this grammar throughout the paper.



\section{Grammarian's wishlist}

To illustrate different needs for different languages, we
take three language-specific phenomena in the scope of our
small grammar: preposition contraction in Dutch, adjective agreement
in Estonian and determiner placement in Basque. We take a single
function as a base, and describe all combinations arguments that are
needed to test the function. If the result of the function is an
inflection table rather than a fully specified result, then we need
several \emph{contexts} to squeeze out all the different forms.
For example, a \t{CN} in English is open for number---\t{house} is
really a table \{\t{Sg =>} \emph{``house''} \t{; Pl =>} \emph{``houses''}\}, and
applying a determiner chooses the right form: \t{DetCN this house}
linearises to \emph{this house} and \t{DetCN these house} linearises
to \emph{these houses}. 



\subsection{Preposition contraction in Dutch} In Dutch, some prepositions should
merge with a single determiner or pronoun, e.g. \emph{met~dit} `with
this' becomes \emph{hiermee} `herewith', but stay independent when the
determiner quantifies a noun, e.g. \emph{met~dit~huis} `with this house'. 
Other prepositions, such as \emph{zonder} `without', do not
contract with any determiners: \emph{zonder~dit} `without this' and
\emph{zonder~dit~huis} `without this house'.
When testing \t{PrepNP}, we would like to see one preposition that
contracts and one that does not, as well as one \t{NP} that is a
single determiner, and one that comes from a noun. Since the result of
\t{PrepNP} is an adverb, which does not inflect any further, we are
happy with just finding the right arguments to \t{PrepNP}, no need for contexts.
In order to catch a bug in the function, or confirm there is none, we
need the following 4 trees: \\
\t{PrepNP} \{ \stackanchor{\tt with}{\tt without} \} 
           \{ \stackanchor{\tt DetNP this}{\tt DetCN this house} \}. 

\subsection{Adjective agreement in Estonian} In Estonian,
most adjectives agree with nouns in case and number in an attributive
position. However, participles are invariable (singular nominative) as 
attributes but inflect regularly in a predicative position, and a set
of invariable adjectives do not inflect in any position. Furthermore,
in 4 of the 14 grammatical cases, even the regular adjectives only
agree with the noun in number, but the case is always genitive.
The following table shows the different behaviours in attributive
position, with \emph{sinine} `blue' as an example of a regular
adjective, and \emph{valmis} `ready' as an invariable.

\begin{table}[h]
\small
\begin{tabular}{cllcllcll}
(1) & sinises & majas & (2) & sinise & majaga & (3) & valmis & majas \\
& blue-{\sc sg.ine} & house-{\sc sg.ine} &  & blue-{\sc sg.gen} & house-{\sc sg.com} &  & ready.{\sc sg.nom} & house-{\sc sg.ine} \\
& \multicolumn{2}{l}{`in a blue house'} &  & \multicolumn{2}{l}{`with a blue house'} &  & \multicolumn{2}{l}{`in a finished house'} \\
& sinistes & majades &  & siniste & majadega &  & valmis & majades \\
& blue-{\sc pl.ine} & house-{\sc pl.ine} &  & blue-{\sc pl.gen} & house-{\sc pl.com} &  & ready.{\sc sg.nom} & house-{\sc pl.ine} \\
& \multicolumn{2}{l}{`in blue houses'} &  & \multicolumn{2}{l}{`with blue
                                         houses'} &  &
                                                     \multicolumn{2}{l}{`in finished houses'}

\end{tabular}
\end{table}

% \begin{table}[h]
% \begin{tabular}{cllcll}
% (1) & suur-e        &  auto-ga       & (2) & suur-te  & auto-de-ga \\ 
%     & big-{\sc gen} &  car-{\sc com} &  & big-{\sc pl.gen} & car-{\sc pl-com} \\
%     & \multicolumn{2}{l}{`with (the) big cars'} 
%                                      &  & \multicolumn{2}{l}{`with (the) big cars'} \\
% \end{tabular}
% \end{table}

%\stackanchor{ \emph{suur-e} \emph{auto-ga}}{\small
%\emph{big}-\textsc{gen} \emph{car}-\textsc{com}} 

%\emph{suur-e} \emph{auto-ga}  \emph{big}-{\sc sg.gen} \emph{car}-\textsc{com} `with a big car'. 
% \noindent Thus in order to test adjectives as attributes, we need an
% example for one of the 10 ``usual'' cases and one of the 4 ``unusual''
% cases, one of each type of adjective, and one of each number. 
\noindent Since we are interested in adjectives, choosing \t{AdjCN} as
the base sounds reasonable---but that only creates an inflection
table, so we must think of a context too. Just like in English, number
comes from the determiner, so we need to wrap the CN in a \t{DetCN}
with two determiners of different number, for instance \t{this} and
\t{these}. But we still need an example for one of the 10 cases with
normal agreement, such as inessive (in something), and one of the 4
cases with restricted agreement, such as comitative (with something).
These cases correspond to the English prepositions \emph{in} and \emph{with},
so in this abstract syntax we can use \t{PrepNP} with the arguments
\t{in} and \t{with}. This is another showcase of the abstraction level
of GF: in the English concrete syntax, \t{Prep} contains a string
such as `in' or `with', and \t{PrepNP} concatenates the string from its
\t{Prep} argument into the resulting adverb, but in Estonian, \t{Prep}
contains a case, and \t{PrepNP} chooses that case from its \t{NP} argument.
The following set of 8 trees creates all the relevant
distinctions\footnote{If the grammar covered predicative
constructions, we would need a participle in the test set. As an
attribute, we do not need both participles and invariables,
because they behave identically, but as a predicative, regular and
participle adjectives behave the same, and differently from
invariable.}: 
 \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
             {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
             {\tt AdjCN}  \{\stackanchor{\tt blue}{\tt ready} \} 
             {\tt house)}.

% If we wanted to test \emph{adjectives} exhaustively, we would need one more context, where
% the adjective is in the predicative position: e.g. `the house is \verb|_|'.
% Furthermore, we need to add a participle to the test cases.
% As an attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable. If we want to test specifically adjectives and not
% \t{PrepNP}, we would prefer to see all types in all positions:
%  \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
%              {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
%              {\tt AdjCN}  \{\stackanchor{\tt blue}{\stackanchor{\tt
%                  ready}{\tt tired}} \} 
%              {\tt house)}.

\subsection{Determiner placement in Basque} In Basque, there are three
different ways to place a determiner into a noun phrase. When a number
(other than 1) or a possessive pronoun acts as a determiner in a
complex noun phrase, it is placed between ``heavy'' modifiers, such as
adverbials or relative clauses, and the rest of the noun
phrase. Demonstrative pronouns, such as \emph{this}, are placed after
all modifiers as an independent word. Number 1, which functions as an
indefinite article, acts like demonstratives, but the definite article
is a suffix. If there is a ``light'' modifier, such as an adjective,
the definite article attaches to the modifier; otherwise it attaches
to the noun. In order to test the implementation of this phenomenon,
we need the following 12 trees:  \\ 
\t{DetCN} \{
\stackanchor{\stackanchor{}{\tts{the}}}{\stackanchor{\tts{this}}{\tts{your}}}
\} \{ \stackanchor{\tt AdvCN on (DetCN the hill)}{$\varnothing$} \} 
\{ \stackanchor{\tt AdjCN small}{$\varnothing$} \}  {\tt house} 

\subsection{??}
\label{sec:wishlist_comments}
The grammar, with only 15-word lexicon and 5 syntactic functions,
generates over 10,000 %17,574
trees\footnote{e.g. {\tt DetCN the (AdvCN (PrepNP on
(DetCN a (AdjCN small hill)) (AdjCN blue house))} `the blue house on a
small hill'}  up to depth 5. 
However, we can test complex morphosyntactic phenomena just with a set
of 4, 8 or 12 trees, depending on the complexity of the language. As
mentioned previously, the base of a test case is one syntactic
function, but often the same sentence ends up showcasing several
functions. In the Estonian example, we start from \t{AdjCN} 
and end up in a context formed by \t{PrepNP}---in fact, these 8 trees
are exactly the same that we would've chosen to test \t{PrepNP}. Thus,
it is possible to shrink the test cases effectively, if one wants to
test the whole grammar at one go.

Of course, such a test set will not catch e.g. individual
misspellings, or more systematic bugs in the morphological
paradigms. But there are easier methods to test for such bugs---our 
goal is to test the more abstract, syntactic phenomena with as few
trees as possible.  



\section{How it works}
\label{sec:details}

GF grammar compiles into a low-level format called PGF. After the
compilation, we get one category for each combination of parameters:
for English adjectives, \texttt{A => A$_{pos}$, A$_{comp}$,
A$_{superl}$}, and for Spanish, \texttt{A => A$_{pos\times{}sg\times{}masc}$, \dots,
A$_{superl\times{}pl\times{}fem}$}. 

Suddenly, we have a bunch of new types, and those are different for
each concrete syntax! The original question ``we need a sample of
nouns/verbs/… that makes sense'' can be simplified ``we need one
noun/verb/… of each type''. The types are determined by the parameters
in the concrete syntax. 

So remember all the hassle when you can't pattern match strings to
know something, but instead you have to define a parameter? This is
actually a nice side effect from that: each parameter contributes to a
new category, so it pays off in generating examples. If the feature is
important for your grammar---say that in language A, negation is
simply attaching the word  ``no'' before the verb, and in language B,
negation changes the word order and the object case. Then in the GF
grammar for language B, we would need a Boolean \texttt{isNeg} field
in the relevant categories, which we then pattern match against in
order to determine the relevant operations. That parameter in the
abstract category translates into different concrete categories, and
that way, when we generate example trees, we make sure to include one
of each. For instance, in language A, we could end up with the trees
``any horse'' and ``all horses'' when testing NPs, but in language B,
the set would also include ``no horses''. 


\paragraph{Test cases} 
The basic unit of a test case is a single constructor, and the first step 
is to build a set of trees using that constructor.
If we are interested in a single lexical item, such as \emph{small}, 
then the subtree \t{small} is the full set of trees. If we choose a function 
with arguments, such as \t{PrepNP}, then we do the following: 
\begin{itemize}
\item For each argument type (\t{Prep} and \t{NP}), compute the
  set of minimal and representative trees. This is a recursive
  process: to compute the set of trees in \t{NP}, we must consider
  all functions that create its argument types (\t{Det} and \t{CN}).
%  until we have a set of lexical functions to choose from. 
\item Take a cross product, prune out redundant combinations, and
  apply the constructor \t{PrepNP} to the resulting set of
  arguments. The pruning method will be described later. 
\end{itemize}

\paragraph{Test cases using \t{AdjCN}} Let us test the function
\t{AdjCN : Adj $\rightarrow$ CN $\rightarrow$ CN}, and take a Spanish
concrete syntax as an example. 
Firstly, we need a minimal and representative set of arguments of types
\t{Adj} and \t{CN}. Consider the nouns first: Spanish has a
grammatical gender, so in order to be representative, we need an
example of both masculine and feminine. Out of the small lexicon,
\t{house} (\emph{casa}) is feminine, and \t{hill} (\emph{cerro}) is
masculine, so we return those two nouns as the full set of argument
trees in \t{CN}. 

Secondly, we consider the adjectives. Most commonly, adjectives follow
the noun, e.g. \emph{casa peque\~{n}a} `small house', but some
adjectives precede the noun, e.g. \emph{buena casa} `good house'. Thus 
in order to cover the full spectrum of adjective placement, we need
one premodifier and one postmodifier adjective. We pick the words
\t{good} and \t{small} as the arguments of type \t{Adj}. 

Now, our full set of test cases are \t{AdjCN} applied to the cross
product of \{\stackanchor{\tt \small good}{\tt \small small}\}
$\times$ \{ \stackanchor{\tt \small house}{\tt \small hill}\}.
Note that \t{CN} is unspecified for number, because it is still waiting for a
determiner (e.g. \t{this} or \t{these}) to complete it into an
\t{NP}. Thus all the test cases contain both singular and plural
variants, and by linearising these 4 trees, we get the 8 strings shown
in Figure~\ref{fig:adjAttr}.

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
\centering
\begin{tabular}{| l | l |}
\hline
\t{AdjCN good house}   & \t{AdjCN good hill} \\ 
\textsc{(sg)} buena casa             & \textsc{(sg)} buen cerro \\
\textsc{(pl)} buenas casas           & \textsc{(pl)} buenos cerros \\ \hline

\t{AdjCN small house}   & \t{AdjCN small hill} \\ 
\textsc{(sg)} casa  peque\~{n}a            & \textsc{(sg)} cerro  peque\~{n}o \\
\textsc{(pl)} casas  peque\~{n}as          & \textsc{(pl)} cerros  peque\~{n}os \\ \hline
\end{tabular}
\caption{Agreement and placement of adjectives in attributive position}
\label{fig:adjAttr}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \todo{A picture of trees with holes}
 \caption{Trees with a hole of type \t{CN}}
\label{fig:treesWithHoles}
\end{minipage}
\end{figure}


\paragraph{Context} 

Now that we have a set of test cases, we create contexts that show all
variation within them. By \emph{context}, we mean simply a tree in
some other category, with a \emph{hole} of type \t{CN}, as shown in
Figure~\ref{fig:treesWithHoles}. 
In this grammar, the only category above is \t{NP}, and there is only
one way that a \t{CN} can end up in an \t{NP}: by using the function
\t{DetCN : Det $\rightarrow$ CN $\rightarrow$ NP}. 

Just like before, we start by creating a representative and minimal
set of arguments of type \t{Det}. So far the relevant features have
been grammatical gender an adjective placement---we have 4 trees with
all combinations of \{masculine, feminine\} and \{pre,post\}. The
resulting trees have \emph{variable} number, but now we have a
category \t{Det} with an inherent number, so we can create the context
that picks the string ``casa  peque\~{n}a'', and another that picks
``casas  peque\~{n}as''. By simple combinatorics, we pick the
representative set of \t{Det} with one singular and one plural
element, e.g. \t{this} and \t{these}, and form two contexts:
\verb|DetCN this _| and  \verb|DetCN these _|. We insert the 4 test
cases into the holes, and get 8 trees in total: \t{\{DetCN this (good
  house), \dots, DetCN these (small hill)\}}. 


\paragraph{Pruning}

For the previous example, we did not need any pruning: the cross
product of all relevant distinctions produced a minimal and
representative set of trees. Now assume we have a larger grammar,
which also covers adjectives in a predicative position:
e.g. \emph{esta casa es peque\~{n}a} `this house is small' and
\emph{esta casa es buena} `this house is good'. The distinction which
made us choose \t{small} and \t{good} in the first place is now gone:
in predicative position, both adjectives behave the same. Thus, in
this larger grammar, when we want to test adjectives, it is necessary
to include two examples when in attributive position, but only one
when in predicative position. We describe exactly how this works in
Section~\ref{sec:details}. 
%In total we would get 12 sentences: the 8 shown previously, and 4 

\section{General features of \pmcfg: unused, equal,
  erased or empty fields}

\todo{rewrite/restructure/merge into something?}

Aside from concrete language-dependent phenomena, there are more
general, engineering questions. For instance, say that our
concrete type for a \t{CN} in Dutch is an inflection table from case
to string, we would like to know whether (a) all string fields make it to
the start category; (b) all fields are distinct; and (c) some fields
are empty. In Dutch, nominative and accusative are only different for
pronouns, so for this grammar we would indeed find out that case is
redundant: all nominative and accusative fields would be
identical. As grammarians, we could decide to keep the distinction for
further extension of the grammar---maybe we want to add pronouns in
the future---or remove it as redundant.

\gf{} has the expressivity of \pmcfg{}, which means that it is
possible to erase arguments: say that there is a bug, \t{AdjCN : Adj
  $\rightarrow$ CN  $\rightarrow$ CN} never actually adds the
adjective to the new \t{CN}, in which case \t{AdjCN blue house} and
\t{house} are linearised identically. Instead of testing every single
function, we would like to know if there are any functions in the
grammar that behave like this.

\section{Use Cases and Evaluation}

Here is a typical use for the tool. 
Let us take the noun phrase grammar for Dutch, and pick a single function,
say \t{AdvCN}. We generate test cases, which include the following
trees: \t{AdvCN (PrepNP next\_to (DetNP your)) hill} `hill next to
yours' and \t{AdvCN (PrepNP next\_to (DetNP your)) house} `house next
to yours'. In Dutch, the words \emph{hill} and \emph{house} have
different genders, and the word \emph{yours} has to agree in gender
with the antecedent. The test cases reveal a bug, where \t{DetNP your}
picks a gender too soon---always a neuter, instead of leaving it open
as an inflection table. We implement a fix by adding gender as a
parameter to the \t{Adv} type, and have \t{AdvCN} choose the correct
form based on the gender of the \t{CN}. 

After implementing the fix, we run a second test case generation: this
time, not meant for human eyes, but just to compare the old and new
versions of the grammar. If we have implemented the fixes to \t{Adv},
\t{AdvCN} and \t{DetNP}


If
the test cases reveal a bug, the grammarian fixes the buggy function,
and then runs another check: this time, generating tests for
\emph{all} functions for both old and new version of the grammar, and
comparing the results to each other. If the fix is implemented
correctly, then the only difference between the old output and the new
output should be in the test cases created from \t{AdvCN}.

Consider the following trees: \t{AdvCN (PrepNP next\_to (DetNP your))
  hill} `hill next to yours' and \t{AdvCN (PrepNP next\_to (DetNP
  your)) house} `house next to yours'. In Dutch, the words \emph{hill}
and \emph{house} have different genders, and the word \emph{yours} has
to agree in gender with the antecedent. The test cases reveal a bug,
and we implement a fix by adding gender as a parameter to the \t{Adv}
type, and have \t{AdvCN} choose the correct form based on the gender
of the \t{CN}. After implementing the fix, we



To cover the whole grammar, the simplest strategy is to generate test
cases for all functions. However, that often leads to redundant trees:
as we noted in Section~\ref{sec:wishlist_comments}, the trees that
are needed to test \t{AdjCN} in Estonian are exactly the same
trees we need to test \t{PrepNP}. 

% The tool is completely
% deterministic, that is, it chooses always the same subtree to
% represent a particular feature. On the one hand, this makes the task
% monotonous for the evaluator, but on the other hand, it makes it
% clearer to see the redundancy: if we have already shown a set of trees
% for \t{PrepNP}, we do not need to show them again for \t{AdjCN}.

As future work, we are planning to add a separate mode for testing the
whole grammar from scratch: create intentionally trees that test
several functions at once.

In order to evaluate our method, we generate test cases for grammars
of varying sizes, using the three languages presented earlier: Dutch,
Estonian and Basque. These languages come from different language
families, and cover a wide range of grammatical complexity. Dutch, an
Indo-European language, has fairly simple nominal and verbal
morphology, but the rules for handling word order, prefixes and
particles in verb phrases are somewhat intricate. Estonian and Basque
both have rich morphology, each featuring 14 nominal cases. However, Basque
verbs are significantly more complex: verbs agree with subject, object
and indirect object, there are more tenses and moods than in either
Dutch or Estonian, and there are several clitics that attach to the
verb (although the grammar implementation only includes \todo{how
  many}). 

Table~\ref{results} shows the number of generated trees for 
in total for all syntactic functions in
the grammar. 

For the smaller grammar, we just report the total number of generated
trees, and for the resource grammar, a few different functions and
finally the total number. Note that we do not consider this an optimal way of
testing a whole resource grammar from scratch---the number of trees is
way too high to be feasible, and the envisioned use case is
this gives merely a baseline
reduction from all possible trees up to a reasonable depth.
We introduce the grammars and comment on the results in the following sections.
\begin{table}[]
\centering
\begin{tabular}{|lll|ll|ll|ll|}
\hline
\multicolumn{3}{|r}{Concrete grammar $\rightarrow$}             & \multicolumn{2}{|c}{Dutch} & \multicolumn{2}{|c}{Basque} & \multicolumn{2}{|c|}{Estonian} \\
$\downarrow$ Abstract grammar & \#funs+lex & \#reasonable trees  &
                                                                 \#total     & \#uniq    & \#total     & \#uniq     & \#total      & \#uniq      \\ \hline
Noun phrases     & 5+15          & \textgreater{}10,000          & 21          & 18          & 33          & 27           & 40           & 36            \\
Phrasebook       & 130+160         & \textgreater{}480,000         & 2006        & 1892        & 2808        & 2650         & 1513         & 1314          \\
Resource grammar & 217+446         & \textgreater{}500 billion & 59316       & 51145       &             &              & 60600        & 38517        \\
\hline
\end{tabular}
\caption{Generating test cases for all syntactic functions}
\label{results}
\end{table}
\subsection{Grammars}

The first grammar is the toy example introduced earlier in this
article: NounPhrases with 5 syntactic functions and 15 words in the
lexicon. We wrote the concrete syntaxes from scratch for each of the
languages, instead of using the full resource grammar and reducing it
to only noun phrases. All three concrete syntaxes were completed
in less than an hour, by an experienced grammarian with knowledge in
all three languages.

The second grammar is a mid-size application grammar: Phrasebook
\cite{ranta2010phrasebook}, with 42 categories such as \t{Person,
  Currency, Price} and \t{Nationality}, 160-word lexicon and 130
functions with arguments. As opposed to the trees that we have seen so far,
which only contain syntactic information, the trees in the Phrasebook
are much more semantic: for example, the abstract tree for the
sentence ``how far is the bar?'' in the Phrasebook is \t{PQuestion
  (HowFar (ThePlace Bar))}, in contrast to the resource grammar tree
{\tt \small UttQS (UseQCl (TTAnt TPres ASimul) PPos (QuestIComp
  (CompIAdv (AdvIAdv how\_IAdv (PositAdvAdj far\_A))) 
  (DetCN (DetQuant DefArt NumSg) (UseN bar\_N))))} for the same
sentence. Limiting up to depth 3, the Phrasebook grammar produces over
480,000 trees\footnote{Application grammars are usually
much more compact than resource grammars, hence depth 3 covers already
a lot of relevant trees.}. All three concrete syntaxes were
implemented using their respective resource grammars; thus if some
Phrasebook function has a bug, say it produces ``Spaniard restaurant''
instead of ``Spanish restaurant'', the problem could be in either grammar.
In the first case, the resource grammar contains both \t{spanish\_A} ``Spanish'' and
\t{spaniard\_N} ``Spaniard'', but the application grammarian has
chosen the wrong function.
In the second case, the application grammarian has correctly chosen
\t{spanish\_A} from the resource grammar, but that word itself is
linearised wrongly into ``Spaniard''.


% \footnote{For the resource grammar, depth
%   3 would be quite small and leave out many completely natural
%   phrases, but the abstract syntax of application grammars is often
%   much more compact.} 

The third grammar is a restricted version of the GF resource grammar,
with 84 categories, 217 syntactic functions and 446 words in the
lexicon. Since all the languages did not have a complete
implementation, we simply took the subset of functions that was
common, and removed manually a couple of rare constructions and words
that are potentially distracting. However, we should not limit the
lexicon too much, because we may miss important distinctions 
in some languages\footnote{To give a hypothetical example, some language may
have a bug that shows up only in animate nouns which end in a
consonant other than \emph{r}}. This subset of the resource grammar
produces hundreds of billions of trees up to depth 5.
%: say, animate and inanimate nouns, ending in front vowel and back vowel.

\subsection{Results}

\paragraph{Execution time} We ran all the experiments on a MacBook Air with 1,7 GHz processor and 8 GB RAM.
For the smaller grammars, all languages took just
seconds to run. For the resource grammar, Dutch and Estonian finished in
3--4 minutes,
% Several other languages, such as English, Swedish, \todo{Hindi,
% Bulgarian, ...} also needed only a few minutes. 
However, the Basque resource grammar is noticeably more complex, and
creating test trees for all functions took several hours. We ran the
experiment in smaller batches, and noticed a lot of variance:
functions that handle e.g. noun phrases, adjectives and adverbs ran in
a few minutes, but a function involving verb phrases could take an
hour just by itself. This is not surprising: Basque verbs agree with
subject, object and indirect object, 

\paragraph{Generated trees} 

We report two numbers: total number of trees, and unique trees. 


\paragraph{Finding bugs} 
We read through the test sentences of the small grammar in all the
three languages. 
For Dutch we had a native speaker; for Estonian a fluent non-native,
and for Basque, a beginner. None of the three grammars had been tested
systematically before---\cite{listenmaa_kaljurand2014} report testing
the morphological paradigms extensively against existing resources,
and for the syntactic functions, a test treebank of a few hundred trees.

\todo{up to line 1977, 11 minutes, finish tomorrow}

On the one hand, test cases based on a single function help to narrow
down the bug: 

as it happens, the tree \t{ACitizen She Indian} had the
wrong form for Indian; one that only works as an attribute, not as a
nationality. (Similar error would be to say e.g. ``a Spaniard
restaurant''.)


Many of the Phrasebook examples felt repetitive, because a lot of
actions, which would be in the lexicon in the resource grammar, were
actually functions with arguments: contrast  \t{Pred She (Compl Like
  Pizza)} with more general functions \t{Pred} and \t{Compl}, to
\t{Like She Pizza}. The latter is useful for more freedom


For the 1314 sentences in Estonian, it took \todo{n} minutes for a
fluent non-native speaker to read through and mark suspicious-looking constructs

smaller grammars, we read through all the example sentences

How many trees you eliminate -- how many trees would you have to read
to confirm that you're correct, and how many trees you need to read
now

\subsection{State of the art}

Traditionally, GF grammars are tested by the grammarians themselves,
much in the way described in the introduction of this article. An example
human-written treebank can be found in \cite[p.~136--142]{khegai2006phd}.
For testing the coverage of the grammars, grammarians have used
treebanks such as the UD treebank \cite{nivre2016ud} and Penn treebank
\cite{marcus1993penntreebank}, and for testing morphology, various open-source resources
have been used, such as morphological lexica from the Apertium
project \cite{forcada2011apertium}.

\todo{Pick one function, get a treebank, see how exhaustively the function
is used in the treebank.}
Check what HPSG, TAG, CCG etc. people use for eval

\cite[pp.~212--213]{butt1999lfg} describes common methods of testing the
{\sc lfg} formalism: similarly to \gf, they use a combination of
human-written test suites meant to cover particular phenomena, and
external larger corpora to test the coverage. As a difference from \gf{}
testing tradition, their human-written test suites include also
ungrammatical sentences: those that the grammar should \emph{not} be
able to parse. However, their tests are only meant for monolingual
grammars, whereas \gf{} tests are for multilingual grammars, so they are
stored as trees. In other words, \gf{} tests only what the grammar
outputs, not what it parses.

Stephan Müller's sentence list testing only weak generative capacity,
this method is testing strong generative capacity


% \begin{itemize}
% \item Cost
%   \begin{itemize}
%   \item time of generating examples
%   \item how many examples generated -- analysis if they're redundant
%   \item time of looking at examples
%   \end{itemize}

% \item Effect
%   \begin{itemize}
%   \item compare against other methods -- what methods?
%   \item For application grammars, if you're writing them from scratch, it is actually pretty feasible to just gt the hell out of it as you write. But this doesn't work for bigger grammars.
%   \item Morphology can be tested efficiently againts any existing morphological analyser. I've used Apertium for Dutch and Basque.
%   \end{itemize}
% \end{itemize}


\section{Discussion}

We have only concentrated on GF grammars so far, but the method works
for any grammar formalism that can be compiled into parallel
multiple CFG (PMCFG) \cite{seki91pmcfg}. The expressive power of PMCFG lies
between mildly context-sensitive and context-sensitive, and thus any
grammar formalism that is less expressive can be expressed as a
PMCFG. This includes CFGs, and mildly context-sensitive formalisms
such as \tag{} \cite{joshi1975tag} and \ccg{} \cite{steedman1988ccg}. GF
already supports reading context-free grammars in labeled BNF format;
so testing any existing CFG is a matter of some pre-processing.

Some existing formalisms such as \hpsg{} and \lfg{} are fully
context-sensitive \todo{cite and find out if there's some subset with
  nice properties}.

\todo{Treebanks can complement the tree generation}

\todo{Other analyses: program analysis, compiler warnings,
  possibilities in GF and not programming languages}

Theoretical question: two grammars that produce the same language but
have different grammar rules.
NounPhrasesEus and NounPhrasesEusBind -- different number of concrete
categories, functions are grouped differently, and
representative+minimal test set is slightly different (smaller in the
one that uses BIND instead of full forms in inflection tables).

We believe this has both language typological and grammar engineering
implications---there is no way to implement Basque in a way that
results in as few example sentences as English, but other resource
grammarians have reported significant differences in complexity
between implementations---\todo{cite Ramona's Romanian RG} reports a
200-time reduction in the number of concrete rules after changing the
implementation of clitics in verb phrases.




% include your own bib file like this:
\bibliographystyle{acl}
\bibliography{bibliography}

\end{document}
