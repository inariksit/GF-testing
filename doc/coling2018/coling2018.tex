%
% File coling2018.tex
%
% Contact: zhu2048@gmail.com & liuzy@tsinghua.edu.cn
%% Based on the style files for COLING-2016, which were, in turn,
%% Based on the style files for COLING-2014, which were, in turn,
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{coling2018}
\usepackage{times}
\usepackage{url}
\usepackage{color}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{stackengine}
\usepackage[normalem]{ulem}
\input{syntaxhilight} % suspicious

\def\t#1{\texttt{#1}}
\def\gf{\textsc{gf}}
\def\pgf{\textsc{pgf}}
\def\lfg{\textsc{lfg}}
\def\ccg{\textsc{ccg}}
\def\tag{\textsc{tag}}
\def\cfg{\textsc{cfg}}
\def\pmcfg{\textsc{pmcfg}}
\def\hpsg{\textsc{hpsg}}
\newcommand{\tts}[1]{{\tt #1}}
%\newcommand{\tts}[1]{{\tt \small #1}}
\newcommand{\todo}[1]{{\color{cyan}\textbf{[TODO: }#1\textbf{]}}}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Automatic systematic test case generation\\for producing reliable grammars}

% \author{Inari Listenmaa and Koen Claessen \\
%   Department of Computer Science and Engineering \\
%   University of Gothenburg and Chalmers University of Technology \\
%   Gothenburg, Sweden \\
%   {\tt inari@chalmers.se, koen@chalmers.se} }


\date{}

\begin{document}
\maketitle
\begin{abstract}
We present a method for finding errors in formalized natural language grammars, by automatically and systematically generating test cases that are intended to be judged by a human oracle. The method works on a per-construction basis; given a construction from the grammar, it generates a finite but complete set of test sentences (typically tens or hundreds), where that construction is used in all possible ways. Our method is an alternative to using a corpus or a treebank, where no such completeness guarantees can be made. The method is language-independent and is implemented for the grammar formalism \pmcfg{}, but also works for weaker grammar formalisms. We evaluate the method on a number of different grammars for different natural languages, with sizes ranging from toy examples to real-world grammars.
\end{abstract}

\section{Introduction}

Grammar engineering has a lot in common with software
engineering. Analogous to a program specification, we use
descriptive grammar books; in place of unit tests, we have gold
standard corpora and test cases for manual inspection.
And just like any software, our grammars still contain bugs:
grammatical sentences that are rejected, ungrammatical
sentences that are parsed, or grammatical sentences that get the wrong
parse.

There are several ways to test grammars that do not involve human
labour. The morphology and lexicon can be compared against existing resources, or
if there are none, a large corpus of any text should give indications
whether the word forms are correct. The same corpus can be used to
test the coverage of the grammar: how many sentences are successfully parsed.
However, often we want information beyond numbers: do the rules we
wrote for relative clauses correctly accept all relative clauses and
nothing else? In other words, we are interested in the strong
generative capacity \cite{chomsky1963} of the grammar, i.e. combinations
of a string and its structural description.

Here is an example of a typical situation we want to improve. Suppose a
grammarian implements relative clauses, and then comes up with a test
suite of sentences with their analyses. The next grammarian implements
relative clauses for another language, and adapts the test set to the
new language. Every time someone touches relative clauses 
in any language, the test suite will be rerun and verified by
someone who knows the language, or compared to the original gold standard, 
if there is one. This scheme can fail for various reasons: 

% When implementing some feature, such as 
% relative clauses, the grammarian comes up with a test suite of 
% sentences that include relative clauses, and stores in the form of 
% abstract syntax trees. In principle, a test suite created for one 
% language can easily be reused for another, because the ASTs are 
% identical.

\begin{itemize}
\item The original list is not exhaustive: for instance, it tests only
``X, who loves me'' but not ``X, whom I love''. 
\item The original list is exhaustive in one language, but not in all:
for instance, it started in English and only included one noun, but in
French it would need at least one masculine and one feminine noun. 
\item The list is overly long, with redundant test cases, and human
testers are not motivated to read through. 
\item A grammarian makes a change somewhere else in the grammar, and
does not realize that it affects relative clauses, and thus does not
rerun the appropriate test suite. 
\end{itemize}

We present a method that addresses these problems, by designing a tool that can automatically generate test cases, given a grammar and a syntactic function that we want to test. Our tool improves on the four weak points in the following way:

\begin{itemize}
\item The set of test cases consists of the syntactic function, applied
  to all relevant arguments and the result is placed in all relevant
  contexts (``relevant'' is defined in
  Section~\ref{sec:details}).
  %Given a grammar and a category, the
  %program can extract all functions that produce or use the given category. 
\item The tests cases are automatically generated for each different
  language. If there is a parameter of gender or noun class in the
  grammar, then the program is guaranteed to choose an example of each
  of them, when it matters.
\item When some feature doesn't matter, the test cases are pruned: for
  example, in English we need to test a reflexive construct with three
  different 3rd person singular subjects, because the object has to
  agree with the subject: ``he sees himself'', ``she sees herself''
  and ``it sees itself''. With a non-reflexive object, it is
  enough to test with only one of \emph{he, she, it}, or any singular
  noun or proper name, because the agreement only shows in the verb
  form, thus generating both ``she sees a dog'' and ``John sees a
  dog'' is redundant.
\item The grammar is a collection of grammatical categories, syntactic
  functions and a lexicon, and everything is interconnected. By
  changing e.g. the category of prepositions, the changes are
  propagated to several functions, e.g. for building adjuncts (``in
  the house'') and complements (``believe in something''). This is
  all part of the grammar, and the chain of effects can be
  automatically traced. 
\end{itemize}

Our concrete implementation is for a particular grammar formalism, namely parallel multiple context-free grammars ({\sc pmcfg}) \cite{seki91pmcfg}, which is the core formalism used by the Grammatical Framework (\gf) \cite{ranta2004gf}. However, the method works for any formalism that is at most as expressive as \pmcfg{}, including formalisms such as Tree-Adjoining Grammar (\tag) \cite{joshi1975tag} and Combinatorial Categorial Grammar (\ccg) \cite{steedman1988ccg}.

\section{Grammatical Framework} \label{sec:gf}
Grammatical Framework (\gf) \cite{ranta2004gf} 
is a framework for building multilingual grammar applications. Its main
components are a functional programming language for writing grammars
and a resource library \cite{ranta2009rgl}, which, as of March 2018,
contains the linguistic details of 40 natural languages. The library
has had over 50 contributors, and it consists of 1900 program modules and 3
million lines of code. \gf{} is well suited for creating
domain-specific systems: examples include mathematics
\cite{caprotti2006webalt}, legal documents \cite{camilleri2017} and
information extraction \cite{Safwat-EtAl:2015:iiWAS}.

A \gf{} grammar consists of an \emph{abstract syntax}, which is a set
of grammatical categories and functions between them, and one or more
\emph{concrete syntaxes}, which describe how the abstract functions
and categories are linearized, i.e. turned into surface strings. The
resulting grammar describes a mapping between concrete language
strings and their corresponding abstract trees. This mapping is
bidirectional---strings can be \emph{parsed} to trees, and trees
\emph{linearized} to strings. As an abstract syntax can have multiple
corresponding concrete syntaxes, the respective languages can be
automatically \emph{translated} from one to the other by first parsing
a string into a tree and then linearizing the obtained tree into a new
string. 

% \todo{this is stolen from Janna's paper 2006--reformulate:}
% \begin{quote} { \em [RGL] Abstract syntax declares universal principles, while language-specific
% parameters are set in concrete syntax. We are not trying to answer the
% general question what constitutes universal grammar and what beyond
% universal grammar differentiates languages from one another. We look
% at \gf{} parallel resource grammars as a way to simplify multilingual
% applications. \dots
% According to the ``division of labor'' principle, resource grammars
% comprise the necessary linguistic knowledge allowing application
% grammarians to concentrate on domain semantics.}
% \end{quote}



%Concrete problems: the kind of bugs we set out to find
%* Empty categories
%* Empty fields
%* Eliminated arguments

%Pick ~3 bugs: 
%what tree was generated? why? likelihood of finding this bug without our method.

%Results


\begin{figure}[h]
  \centering

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{abstract }\DataTypeTok{NounPhrases} \FunctionTok{=} \NormalTok{\{}
  \NormalTok{flags startcat }\FunctionTok{=} \DataTypeTok{NP} \NormalTok{;}
  \KeywordTok{cat}
    \DataTypeTok{NP} \NormalTok{; }\DataTypeTok{Adv} \NormalTok{;                   }\CommentTok{-- Non-terminal categories}
    \DataTypeTok{CN} \NormalTok{; }\DataTypeTok{Det} \NormalTok{; }\DataTypeTok{Adj} \NormalTok{; }\DataTypeTok{Prep} \NormalTok{;      }\CommentTok{-- Terminal (lexical) categories}
  \KeywordTok{fun}
    \NormalTok{DetNP} \FunctionTok{:} \DataTypeTok{Det} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;          }\CommentTok{-- e.g. "this"; "yours"}
    \NormalTok{DetCN} \FunctionTok{:} \DataTypeTok{Det} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;    }\CommentTok{-- e.g. "this house"}
    \NormalTok{PrepNP} \FunctionTok{:} \DataTypeTok{Prep} \OtherTok{->} \DataTypeTok{NP} \OtherTok{->} \DataTypeTok{Adv} \NormalTok{; }\CommentTok{-- e.g. "without the house"}
    \NormalTok{AdjCN} \FunctionTok{:} \DataTypeTok{Adj} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;    }\CommentTok{-- e.g. "small house"}
    \NormalTok{AdvCN} \FunctionTok{:} \DataTypeTok{Adv} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;    }\CommentTok{-- e.g. "house on a hill"}

    \NormalTok{a, the, this, these, your }\FunctionTok{:} \DataTypeTok{Det} \NormalTok{;}
    \NormalTok{good, small, blue, ready }\FunctionTok{:} \DataTypeTok{Adj} \NormalTok{;}
    \NormalTok{house, hill }\FunctionTok{:} \DataTypeTok{CN} \NormalTok{;}
    \NormalTok{in, on, with, without }\FunctionTok{:} \DataTypeTok{Prep} \NormalTok{; }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

% \begin{verbatim}
% abstract NounPhrases = {
%   flags startcat = NP ;
%   cat
%     NP ; Adv ;                   -- Non-terminal categories
%     CN ; Det ; Adj ; Prep ;      -- Terminal (lexical) categories
%   fun
%     DetNP : Det -> NP ;          -- e.g. "this"; "yours"
%     DetCN : Det -> CN -> NP ;    -- e.g. "this house"
%     PrepNP : Prep -> NP -> Adv ; -- e.g. "without the house"
%     AdjCN : Adj -> CN -> CN ;    -- e.g. "small house"
%     AdvCN : Adv -> CN -> CN ;    -- e.g. "house on a hill"

%     a, the, this, these, your : Det ;
%     good, small, blue, ready : Adj ;
%     house, hill, cake : CN ;
%     in, on, with, without : Prep ; 
% }
% \end{verbatim}
  \caption{\gf{} grammar for noun phrases}
\label{fig:exampleGrammar}
\end{figure}

Figure~\ref{fig:exampleGrammar} shows a small example of a \gf{} abstract
grammar. The grammar generates noun phrases for a lexicon of 15
words (\emph{a, the, \dots, without}) in four lexical categories,
and five functions to construct phrases. \t{CN} stands for common
noun, and it can be modified by arbitrarily many adjectives (\t{Adj}),
e.g. \emph{small blue house} is an English linearisation of the
abstract syntax tree \t{AdjCN small (AdjCN blue house)}. A \t{CN} is
quantified into a noun phrase (\t{NP}) by adding a determiner
(\t{Det}), e.g. \emph{the small house} corresponds to tree \t{DetCN the (AdjCN small
  house)}. Alternatively, a \t{Det} can also become an independent
noun phrase (as in, \emph{(I like) this} instead of \emph{(I like) this
  house}) using the constructor \t{DetNP}. Finally, we can form an
adverb (\t{Adv}) by combining a preposition (\t{Prep}) with an \t{NP},
and those adverbs can modify yet another \t{CN}. 
We refer to this grammar throughout the paper.

As examples that help illustrate different testing needs for different languages, let us take three language-specific phenomena in the scope of our
small grammar: preposition contraction in Dutch, adjective agreement
in Estonian and determiner placement in Basque.

\subsection{Preposition contraction in Dutch} In Dutch, some prepositions should
merge with a single determiner or pronoun, e.g. \emph{met~dit} `with
this' becomes \emph{hiermee} `herewith', but stay independent when the
determiner quantifies a noun, e.g. \emph{met~dit~huis} `with this house'. 
Other prepositions, such as \emph{zonder} `without', do not
contract with any determiners: \emph{zonder~dit} `without this' and
\emph{zonder~dit~huis} `without this house'.
When testing \t{PrepNP}, we would like to see one preposition that
contracts and one that does not, as well as one \t{NP} that is a
single determiner, and one that comes from a noun. Since the result of
\t{PrepNP} is an adverb, which does not inflect any further, we are
happy with just finding the right arguments to \t{PrepNP}, no need for contexts.
In order to catch a bug in the function, or confirm there is none, we
need the following 4 trees: \\
\t{PrepNP} \{ \stackanchor{\tt with}{\tt without} \} 
           \{ \stackanchor{\tt DetNP this}{\tt DetCN this house} \}. 

\subsection{Adjective agreement in Estonian} In Estonian,
most adjectives agree with nouns in case and number in an attributive
position. However, participles are invariable (singular nominative) as 
attributes but inflect regularly in a predicative position, and a set
of invariable adjectives do not inflect in any position. Furthermore,
in 4 of the 14 grammatical cases, even the regular adjectives only
agree with the noun in number, but the case is always genitive.
The following table shows the different behaviours in attributive
position, with \emph{sinine} `blue' as an example of a regular
adjective, and \emph{valmis} `ready' as an invariable.

\begin{table}[h]
\small
\begin{tabular}{cllcllcll}
(1) & sinises & majas & (2) & sinise & majaga & (3) & valmis & majas \\
& blue-{\sc sg.ine} & house-{\sc sg.ine} &  & blue-{\sc sg.gen} & house-{\sc sg.com} &  & ready.{\sc sg.nom} & house-{\sc sg.ine} \\
& \multicolumn{2}{l}{`in a blue house'} &  & \multicolumn{2}{l}{`with a blue house'} &  & \multicolumn{2}{l}{`in a finished house'} \\
& sinistes & majades &  & siniste & majadega &  & valmis & majades \\
& blue-{\sc pl.ine} & house-{\sc pl.ine} &  & blue-{\sc pl.gen} & house-{\sc pl.com} &  & ready.{\sc sg.nom} & house-{\sc pl.ine} \\
& \multicolumn{2}{l}{`in blue houses'} &  & \multicolumn{2}{l}{`with blue
                                         houses'} &  &
                                                     \multicolumn{2}{l}{`in finished houses'}

\end{tabular}
\end{table}

% \begin{table}[h]
% \begin{tabular}{cllcll}
% (1) & suur-e        &  auto-ga       & (2) & suur-te  & auto-de-ga \\ 
%     & big-{\sc gen} &  car-{\sc com} &  & big-{\sc pl.gen} & car-{\sc pl-com} \\
%     & \multicolumn{2}{l}{`with (the) big cars'} 
%                                      &  & \multicolumn{2}{l}{`with (the) big cars'} \\
% \end{tabular}
% \end{table}

%\stackanchor{ \emph{suur-e} \emph{auto-ga}}{\small
%\emph{big}-\textsc{gen} \emph{car}-\textsc{com}} 

%\emph{suur-e} \emph{auto-ga}  \emph{big}-{\sc sg.gen} \emph{car}-\textsc{com} `with a big car'. 
% \noindent Thus in order to test adjectives as attributes, we need an
% example for one of the 10 ``usual'' cases and one of the 4 ``unusual''
% cases, one of each type of adjective, and one of each number. 
\noindent Since we are interested in adjectives, choosing \t{AdjCN} as
the base sounds reasonable---but that only creates an inflection
table, so we must think of a context too. Just like in English, number
comes from the determiner, so we need to wrap the \t{CN} in a \t{DetCN}
with two determiners of different number, for instance \t{this} and
\t{these}. But we still need an example for one of the 10 cases with
normal agreement, such as inessive (in something), and one of the 4
cases with restricted agreement, such as comitative (with something).
These cases correspond to the English prepositions \emph{in} and \emph{with},
so in this abstract syntax we can use \t{PrepNP} with the arguments
\t{in} and \t{with}. This is another showcase of the abstraction level
of \gf{}: in the English concrete syntax, \t{Prep} contains a string
such as `in' or `with', and \t{PrepNP} concatenates the string from its
\t{Prep} argument into the resulting adverb, but in Estonian, \t{Prep}
contains a case, and \t{PrepNP} chooses that case from its \t{NP} argument.
The following set of 8 trees creates all the relevant
distinctions:
% \footnote{If the grammar covered predicative
% constructions, we would need a participle in the test set. As an
% attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable.}: 
 \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
             {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
             {\tt AdjCN}  \{\stackanchor{\tt blue}{\tt ready} \} 
             {\tt house)}.

% If we wanted to test \emph{adjectives} exhaustively, we would need one more context, where
% the adjective is in the predicative position: e.g. `the house is \verb|_|'.
% Furthermore, we need to add a participle to the test cases.
% As an attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable. If we want to test specifically adjectives and not
% \t{PrepNP}, we would prefer to see all types in all positions:
%  \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
%              {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
%              {\tt AdjCN}  \{\stackanchor{\tt blue}{\stackanchor{\tt
%                  ready}{\tt tired}} \} 
%              {\tt house)}.

\subsection{Determiner placement in Basque} In Basque, there are three
different ways to place a determiner into a noun phrase. When a number
(other than 1) or a possessive pronoun acts as a determiner in a
complex noun phrase, it is placed between ``heavy'' modifiers, such as
adverbials or relative clauses, and the rest of the noun
phrase. Demonstrative pronouns, such as \emph{this}, are placed after
all modifiers as an independent word. Number 1, which functions as an
indefinite article, acts like demonstratives, but the definite article
is a suffix. If there is a ``light'' modifier, such as an adjective,
the definite article attaches to the modifier; otherwise it attaches
to the noun. In order to test the implementation of this phenomenon,
we need the following 12 trees:  \\ 
\t{DetCN} \{
\stackanchor{\stackanchor{}{\tts{the}}}{\stackanchor{\tts{this}}{\tts{your}}}
\} \{ \stackanchor{\tt AdvCN on (DetCN the hill)}{$\varnothing$} \} 
\{ \stackanchor{\tt AdjCN small}{$\varnothing$} \}  {\tt house} 


\subsection{Using our tool} We have seen that, in order to test
whether or not we have implemented a linguistic phenomenon correctly,
we take a single function as a base, and describe all combinations of
arguments that are needed to test the function. If the result of the
function is an inflection table rather than a fully specified result,
then we need several \emph{contexts} to squeeze out all the different
forms. For example, a \t{CN} in English is open for number---\t{house}
is really a table \{\t{Sg =>} \emph{``house''} \t{; Pl =>}
\emph{``houses''}\}, and applying a determiner chooses the right form:
\t{DetCN this house} linearizes to \emph{this house} and \t{DetCN
  these house} linearizes to \emph{these houses}. 

\label{sec:wishlist_comments}
The example grammar, with only 15-word lexicon and 5 syntactic functions,
generates over 10,000 %17,574
trees\footnote{e.g. {\tt DetCN the (AdvCN (PrepNP on
(DetCN a (AdjCN small hill)) (AdjCN blue house))} `the blue house on a
small hill'}  up to depth 5. 
However, as we have seen in the examples above, we can test complex morphosyntactic phenomena just with a set
of 4, 8 or 12 trees, depending on the complexity of the language.

As mentioned previously, the base of a test case is one syntactic
function, but often the same sentence ends up showcasing several
functions. In the Estonian example, we start from \t{AdjCN} 
and end up in a context formed by \t{PrepNP}---in fact, these 8 trees
are exactly the same that we would've chosen to test \t{PrepNP}. Thus,
it is possible to shrink the test cases effectively, if one wants to
test the whole grammar at one go.

Of course, such a test set will not catch e.g. individual
misspellings, or more systematic bugs in the morphological
paradigms. But there are easier methods to test for such bugs---our 
goal is to test the more abstract, syntactic phenomena with as few
trees as possible.  

\section{How the tool works}
\label{sec:details}

A \gf{} grammar compiles into a low-level format called \pgf{}
(``Portable Grammar Format''), which is processed by our tool. For
each category in the original grammar, the \gf{} compiler introduces a
new category in the \pgf{} for each combination of parameters. For
example for English adjectives, we get ${\tt A \Rightarrow \{ \tt A_{pos}, A_{comp}, A_{superl}}$\}, and for Spanish,
${\tt A \Rightarrow \{ A_{pos\times{}sg\times{}masc}, \dots, A_{superl\times{}pl\times{}fem}}$\}. 

This compilation step can dramatically increase the number of categories of the grammar, but it also removes the need for dealing with these parameters explicitly when we generate test cases. Instead, each syntactic function from the original grammar turns into multiple syntactic functions into the \pgf{} -- one for each combination of parameters of its arguments.

We now describe the generation of test cases for a given syntactic function. We assume that all test cases are trees with the same start (top-level) category, such as \t{NP} in our example grammar, or \t{S} (for sentence) for more general grammars. The requirement is that the start category is linearized as one string only. (In a \pmcfg{}, categories in general can be linearized to vectors of strings, which is perhaps unsuitable for test cases that are presented to a human.)

\paragraph{Enumerate functions} As we explained before, each syntactic function turns into multiple versions, one for each combination of parameters of its arguments. We test each of these versions seperately. This enumeration is the main reason we see several test cases in the examples in Section~\ref{sec:gf}.

In order to construct trees that use the syntactic function, we need to supply it with \emph{arguments}, as well as put the resulting tree into a \emph{context} that produces a tree in the correct start category.

\paragraph{Enumerate arguments} Some syntactic functions are simply a single lexical item (for example the word \emph{small}); in this case just the tree \t{small} is our answer. If we choose a function with arguments, such as for example \t{PrepNP}, then we have to supply it with argument trees. Each argument tree needs to be a tree belonging to the right category (in the example, \t{Prep} and \t{NP}, respectively).

When we test a function, we want to see whether or not it uses the right information from its arguments, in the right way. The information that a syntactic function uses is any of the strings that come from linearizing its arguments. In order to be able to see which string in the result comes from which string from which arguments, we want to generate test cases that only contain unique strings (no duplicates).

For example, when we test a preposition together with a noun, we want to pick a noun that actually has different forms (unique strings) for different prepositions, rather than having identical forms, because the human would not be able to see if the \t{PrepVP} function picked the wrong form.

It is often possible to generate one combination of arguments where all strings in the linearizations are different. However, it is not always possible to this, which is why we in general aim to generate a set of combinations of arguments, where for each pair of strings from the arguments, there is always one test case where those strings are different. In this way, if the syntactic function contains a mistake, there is always one test case that reveals it.

\paragraph{Example: Test cases using \t{AdjCN}} Let us test the function
\t{AdjCN : Adj $\rightarrow$ CN $\rightarrow$ CN}, and take a Spanish
concrete syntax as an example. 
Firstly, we need a minimal and representative set of arguments of types
\t{Adj} and \t{CN}. Consider the nouns first: Spanish has a
grammatical gender, so in order to be representative, we need an
example of both masculine and feminine. Out of the small lexicon,
\t{house} (\emph{casa}) is feminine, and \t{hill} (\emph{cerro}) is
masculine, so we return those two nouns as the full set of argument
trees in \t{CN}. 

Secondly, we consider the adjectives. Most commonly, adjectives follow
the noun, e.g. \emph{casa peque\~{n}a} `small house', but some
adjectives precede the noun, e.g. \emph{buena casa} `good house'. Thus 
in order to cover the full spectrum of adjective placement, we need
one premodifier and one postmodifier adjective. We pick the words
\t{good} and \t{small} as the arguments of type \t{Adj}. 

Now, our full set of test cases are \t{AdjCN} applied to the cross
product of \{\stackanchor{\tt \small good}{\tt \small small}\}
$\times$ \{ \stackanchor{\tt \small house}{\tt \small hill}\}.
Note that \t{CN} is unspecified for number, because it is still waiting for a
determiner (e.g. \t{this} or \t{these}) to complete it into an
\t{NP}. Thus all the test cases contain both singular and plural
variants, and by linearizing these 4 trees, we get the 8 strings shown
in Figure~\ref{fig:adjAttr}.

\begin{figure}
\centering
\centering
\begin{tabular}{| l | l |}
\hline
\t{AdjCN good house}   & \t{AdjCN good hill} \\ 
\textsc{(sg)} buena casa             & \textsc{(sg)} buen cerro \\
\textsc{(pl)} buenas casas           & \textsc{(pl)} buenos cerros \\ \hline

\t{AdjCN small house}   & \t{AdjCN small hill} \\ 
\textsc{(sg)} casa  peque\~{n}a            & \textsc{(sg)} cerro  peque\~{n}o \\
\textsc{(pl)} casas  peque\~{n}as          & \textsc{(pl)} cerros  peque\~{n}os \\ \hline
\end{tabular}
\caption{Agreement and placement of adjectives in attributive position}
\label{fig:adjAttr}
\end{figure}

\paragraph{Enumerate contexts} The third and last enumeration we perform when generating test cases is to generate all possible \emph{uses} of a function. After we provide a function with arguments, we need to put the result into a context, so that we can generate a single string from the result (a sentence). We do this for all trees we have generated so far.

The important thing here is that the generated set of contexts shows all the possible different ways the tree can be used. For example, for a test tree with an inflection table of size 4, we would generate 4 different sentences in which each of the 4 inflections is used.

By \emph{context}, we mean a tree in
the start category, with a \emph{hole} of type \t{CN}. A tree of type \t{CN} can be plugged into the hole to form a tree in the start category. In this grammar, the only category above \t{CN} is \t{NP}, and there is only
one way that a \t{CN} can end up in an \t{NP}: by using the function
\t{DetCN : Det $\rightarrow$ CN $\rightarrow$ NP}. 

Let us return to our running example. So far the relevant features have
been grammatical gender an adjective placement---we have 4 trees with
all combinations of \{masculine, feminine\} and \{pre,post\}. The
resulting trees have \emph{variable} number, and we need to generate contexts that specify that number. In the \pgf{}, the function \t{DetCN} actually comes in two versions: one for singular and one for plural determiners. Both of these use their arguments in different ways (different strings from the hole appear in the result). So, both versions of \t{DetCN} lead to one context each. The final contexts are \verb|DetCN this _| and  \verb|DetCN these _|. Note that we do not have to enumerate all possible first arguments to \t{DetCN}. We insert the 4 test
cases into the holes, and get 8 trees in total: \t{\{DetCN this (good
  house), \dots, DetCN these (small hill)\}}. 

So, what we want to compute is, given the result category T of the syntactic function, and the start category S of the grammar, a minimal set of contexts in the start category S with hole of type T, such that any string appearing in the linearization of T also appears somewhere in the linearization of S. We compute this by setting up a system of equations for each category C in the grammar: for each C, we define all the relevant contexts with hole type C in terms of all the relevant contexts with hole type C' for other categories C' that use C. So, the answer for each category is expressed in terms of the answer for other categories. In general, this system of equations is \emph{recursive}, and we use a fixpoint iteration to compute the smallest solution.

\paragraph{Pruning} For the previous example, we did not need any pruning: the cross
product of all relevant distinctions produced a minimal and
representative set of trees. Now assume we have a larger grammar,
which also covers adjectives in a predicative position:
e.g. \emph{esta casa es peque\~{n}a} `this house is small' and
\emph{esta casa es buena} `this house is good'. The distinction which
made us choose \t{small} and \t{good} in the first place is now gone:
in predicative position, both adjectives behave the same. Thus, in
this larger grammar, when we want to test adjectives, it is necessary
to include two examples when in attributive position, but only one
when in predicative position. 


\section{General features of \pmcfg: unused, equal,
  erased or empty fields}

Aside from concrete language-dependent phenomena, there are more
general, engineering questions a grammar writer may ask. For instance, say that our
concrete type for a \t{CN} in Dutch is an inflection table from case
to string, we would like to know if (a) a given string field is unreachable from the start category; (b) any two fields always contain the same string; or (c) some fields
are always the empty string. A yes answer to any of these may indicate a bug in the grammar.

In Dutch, nominative and accusative are only different for
pronouns, so for this grammar we would indeed find out that case is
redundant: all nominative and accusative fields would be
identical. As grammarians, we could decide to keep the distinction for
further extension of the grammar---maybe we want to add pronouns in
the future---or remove it as redundant.

\gf{} has the expressivity of \pmcfg{}, which means that it is
possible to erase arguments: say that there is a bug, \t{AdjCN : Adj
  $\rightarrow$ CN  $\rightarrow$ CN} never actually adds the
adjective to the new \t{CN}, in which case \t{AdjCN blue house} and
\t{house} are linearized identically. Instead of testing every single
function, we would like to know if there are any functions in the
grammar that behave like this.

The analyses mentioned in this section are implemented in a similar way to the method for enumerating all contexts.

\section{Use cases and evaluation}

Here is a typical use for the tool. 
Let us take the noun phrase grammar for Dutch, and pick a single function,
say \t{AdvCN}. We generate test cases, which include the following
trees: 
\begin{itemize}
\item \t{AdvCN (PrepNP next\_to (DetNP your)) hill} `hill next to
yours'
\item \t{AdvCN (PrepNP next\_to (DetNP your)) house} `house next
to yours'
\end{itemize}
In Dutch, the words \emph{hill} and \emph{house} have different
genders, and the word \emph{yours} has to agree in gender 
with the antecedent: \emph{(de) heuvel naast de jouwe} and \emph{(het)
  huis naast het jouwe}. The test cases reveal a bug, where \t{DetNP your} 
picks a gender too soon, instead of leaving it open in an inflection
table. We implement a fix by adding gender as a parameter to the
\t{Adv} type, and have \t{AdvCN} choose the correct form based on the gender of the \t{CN}. 

After implementing the fix, we run a second test case generation: this
time, not meant for human eyes, but just to compare the old and new
versions of the grammar. We want to make sure that our changes 
%to \t{Adv}, \t{AdvCN} and \t{DetNP} 
have not caused new bugs in other functions. The simplest strategy is
to generate test cases for \emph{all} functions in both grammars, and
only show those outputs that differ between the grammars. After our
fixes, we get the following differences: 

\begin{itemize}
\item \t{DetCN the (AdvCN (PrepNP next\_to (DetNP your)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel naast {\bf  het} jouwe}}
   \item \emph{de heuvel naast {\bf  de} jouwe}
  \end{itemize}
\item \t{DetCN the (AdvCN (PrepNP without (DetNP this)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel zonder {\bf  dit}}}
   \item \emph{de heuvel zonder {\bf  deze}}
  \end{itemize}
\end{itemize}

\noindent We notice a side effect that we may not have thought of: the
gender is retained in all adverbs made of NPs made of determiners, so
now it has become impossible to say ``the hill without \emph{that}'' and
pointing to a house. So we do another round of modifications, compute
the difference (to the original grammar or to the intermediate), and
see if something else broke.


% The tool is completely
% deterministic, that is, it chooses always the same subtree to
% represent a particular feature. On the one hand, this makes the task
% monotonous for the evaluator, but on the other hand, it makes it
% clearer to see the redundancy: if we have already shown a set of trees
% for \t{PrepNP}, we do not need to show them again for \t{AdjCN}.

\begin{table}[h]
\centering
\begin{tabular}{|lll|ll|ll|ll|}
\hline
\multicolumn{3}{|r}{Concrete grammar $\rightarrow$}              &
                                                                   \multicolumn{2}{|c}{\bf Dutch} & \multicolumn{2}{|c}{\bf Basque} & \multicolumn{2}{|c|}{\bf Estonian} \\
$\downarrow$ Abstract grammar & \#funs+lex & \#trees  &
                                                                 \#total & \#uniq & \#total & \#uniq  & \#total  & \#uniq \\ \hline
{\bf Noun phrases}     & 5+15          & \textgreater{}10,000          & 21    & 18     & 33      & 27      & 40       & 36     \\ \hline
{\bf Phrasebook}       & 130+160         & \textgreater{}480,000       & 2006  & 1892   & 2808    & 2650    & 1513     & 1314   \\ \hline
{\bf Resource grammar} & 217+446         & \textgreater{}500 billion   & 59,316 & 51,145  & 278,092  & 216,058  & 60,600    & 38,517   \\ \hline
\end{tabular}
\caption{Test cases for all functions in three grammars}
\label{results}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|l|ll|ll|ll|}
\hline
{\bf Resource grammar function} &\multicolumn{2}{|c}{\bf Dutch} &
                                                                  \multicolumn{2}{|c}{\bf Basque} & \multicolumn{2}{|c|}{\bf Estonian} \\
                               &  \#trees in contexts & \#combinations of args
                                                                                                  &\#t
                                                                                                    
                               & \#c & \#t &
                                                                    \#c\\ \hline
\t{ComparA} `younger than me'  &  11      & 3     & 36     & 6     & 21      & 3   \\
% \t{FunRP~~} `mother of whom'  &  20      & 5     & 26     & 26    & 708     & 116 \\
\t{RelNP~~} `a cat that I saw' &  25      & 9     & 90     & 10    & 123     & 12 \\
 \t{ReflVP~} `see myself'      &  1655    & 23    & 10838  &  128  &1608     & 13   \\


\hline
\end{tabular}
\caption{Test cases for some individual functions in the resource grammar}
\label{results_indiv}
\end{table}

In order to evaluate our method, we generate test cases for grammars
of varying sizes, using the three languages presented earlier: Dutch,
Estonian and Basque. These languages come from different language
families, and cover a wide range of grammatical complexity. Dutch, an
Indo-European language, has fairly simple nominal and verbal
morphology, but the rules for handling word order, prefixes and
particles in verb phrases are somewhat intricate. Estonian and Basque
both have rich morphology, each featuring 14 nominal cases, but Basque
verb morphology is much more complex, with agreement in subject,
object and indirect object. Contrary to our expectations, we found
Dutch and Estonian behaving similarly to each other and Basque
significantly worse, both in execution time and examples generated.

Table~\ref{results} shows the number of generated trees for 
in total for all syntactic functions in the three grammars, and
Table~\ref{results_indiv} shows some example functions from the resource grammar. 
As stated earlier, we do not consider generating test cases for all
functions an optimal way of testing a whole resource grammar from scratch;
this gives merely a baseline reduction from all possible trees up to a
reasonable depth. We introduce the grammars and comment on the results
in the following sections. 

\subsection{Grammars}

The first grammar is the toy example introduced earlier in this
article: NounPhrases with 5 syntactic functions and 15 words in the
lexicon. We wrote the concrete syntaxes from scratch for each of the
languages, instead of using the full resource grammar and reducing it
to only noun phrases. All three concrete syntaxes were completed
in less than an hour, by an experienced grammarian with knowledge in
all three languages.

The second grammar is a mid-size application grammar: Phrasebook
\cite{ranta2010phrasebook}, with 42 categories such as \t{Person,
  Currency, Price} and \t{Nationality}, 160-word lexicon and 130
functions with arguments. As opposed to the trees that we have seen so far,
which only contain syntactic information, the trees in the Phrasebook
are much more semantic: for example, the abstract tree for the
sentence ``how far is the bar?'' in the Phrasebook is \t{PQuestion
  (HowFar (ThePlace Bar))}, in contrast to the resource grammar tree
{\tt \small UttQS (UseQCl (TTAnt TPres ASimul) PPos (QuestIComp
  (CompIAdv (AdvIAdv how\_IAdv (PositAdvAdj far\_A))) 
  (DetCN (DetQuant DefArt NumSg) (UseN bar\_N))))} for the same
sentence. Limiting up to depth 3, the Phrasebook grammar produces over
480,000 trees\footnote{Application grammars are usually
much more compact than resource grammars, hence depth 3 covers already
a lot of relevant trees.}.

%  All three concrete syntaxes were
% implemented using their respective resource grammars; thus if some
% Phrasebook function has a bug, say it produces ``Spaniard restaurant''
% instead of ``Spanish restaurant'', the problem could be in either grammar.
% In the first case, the resource grammar contains both \t{spanish\_A} ``Spanish'' and
% \t{spaniard\_N} ``Spaniard'', but the application grammarian has
% chosen the wrong function.
% In the second case, the application grammarian has correctly chosen
% \t{spanish\_A} from the resource grammar, but that word itself is
% linearized wrongly into ``Spaniard''.


The third grammar is a restricted version of the \gf{} resource grammar,
with 84 categories, 217 syntactic functions and 446 words in the
lexicon. Since all the languages did not have a complete
implementation, we simply took the subset of functions that was
common, and removed manually a couple of rare constructions and words
that are potentially distracting. However, we should not limit the
lexicon too much, because we may miss important distinctions 
in some languages---to give a hypothetical example, some grammar may
have a bug that shows up only in animate nouns which end in a
consonant. This subset of the resource grammar produces hundreds of
billions of trees up to depth 5. 
%: say, animate and inanimate nouns, ending in front vowel and back vowel.

\subsection{Results}

\paragraph{Execution time} We ran all the experiments on a MacBook Air with 1,7 GHz processor and 8 GB RAM.
For the smaller grammars, all languages took just
seconds to run. For the resource grammar, Dutch and Estonian finished in
3--4 minutes.
However, the Basque resource grammar is noticeably more complex, and
creating test trees for all functions took several hours. We ran the
experiment in smaller batches over two days, and noticed a lot of
variance: functions that handle e.g. noun phrases, adjectives and
adverbs ran in a few minutes, but a function involving verb phrases
could take an hour just by itself. 


% \paragraph{Generated trees} 

% \todo{write about this in some later version}
% We believe this has both language typological and grammar engineering
% implications---there is no way to implement Basque in a way that
% results in as few example sentences as English, but other resource
% grammarians have reported significant differences in complexity
% between implementations---\cite{enache2010} reports a
% 200-time reduction in the number of concrete rules after changing the
% implementation of clitics in verb phrases.




\paragraph{Finding bugs} 
We read through the test sentences of the small grammar in all the
three languages. 
For Dutch we had a native speaker; for Estonian an intermediate non-native,
and for Basque, a beginner. None of the three grammars had been tested
systematically before---\cite{listenmaa_kaljurand2014} report testing
the morphological paradigms extensively against existing resources,
and syntactic functions with a treebank of 425 trees.

We have been developing the tool by testing it on the Dutch resource
grammar, and during 4 months, we have committed 16 bugfixes in the
\gf{} main repository. (In the name of honesty, a few of the bugs were
caused by our earlier ``fixes''---that was before we had implemented
the comparison against an older version of the grammar!) 

The Basque resource grammar is still a work in progress, and the
test sentences showed serious problems in morphology.
We thought it premature to get a fluent speaker to evaluate the grammar,
because the errors in morphology would probably make it
difficult to assess syntax separately. We think that the best course
of action is to evaluate the morphological paradigms against existing
resources, fix the implementation, and then concentrate on syntax.
The Phrasebook was implemented using the resource grammar, so the
same problems apply.

We read through the first 500 sentences from Estonian Phrasebook,
which took around 20 minutes. We found 3 errors in the inflection of
individual words (they did not come from the resource lexicon, which
was tested, but were implemented separately in the grammar); one error
of type ``Spaniard restaurant'', and one suggestion for a more idiomatic
construction. As expected, Phrasebook sentences were easier to read,
and made more sense semantically than sentences from the resource
grammar. %, which is only supposed to contain syntactic functions. 


%\todo{up to line 1977, 11 minutes, finish tomorrow}
%For the 1314 sentences in Estonian, it took \todo{n} minutes for a
%fluent non-native speaker to read through and mark suspicious-looking constructs

\subsection{Previous work}

Traditionally, \gf{} grammars are tested by the grammarians themselves,
much in the way described in the introduction of this article. An example
human-written treebank can be found in \cite[p.~136--142]{khegai2006phd}.
For testing the coverage of the grammars, grammarians have used
treebanks such as the UD treebank \cite{nivre2016ud} and Penn treebank
\cite{marcus1993penntreebank}, and for testing morphology, various open-source resources
have been used, such as morphological lexica from the Apertium
project \cite{forcada2011apertium}.

%\todo{Pick one function, get a treebank, see how exhaustively the
%function is used in the treebank.}


As an example of other grammar formalisms,
\cite[pp.~212--213]{butt1999lfg} describe common methods of testing
the {\sc lfg} formalism: similarly to \gf, they use a combination of
human-written test suites meant to cover particular phenomena, and
external larger corpora to test the coverage. As a difference from \gf{}
testing tradition, their human-written test suites include also
ungrammatical sentences: those that the grammar should \emph{not} be
able to parse. However, their tests are only meant for monolingual
grammars, whereas \gf{} tests are for multilingual grammars, so they are
stored as trees. In other words, \gf{} tests only what the grammar
outputs, not what it parses.
\cite{bender2010} describe a system for creating and testing \hpsg{} \cite{pollard1994hpsg}
grammars, by using a detailed questionnaire about the features of the
given language. This system achieves both generating the grammar rules
and testing them simultaneously, whereas our method relies on an
existing grammar. On the other hand, our system is more general to any
kinds of grammars, including application grammars where the
distinctions are not syntactic but semantic.




\section{Conclusion and future work}

We have presented method for automatically generating minimal and exhaustive sets of test cases for testing grammars.  We have found the tool useful in large-scale grammar writing, in a context where grammars need to be \emph{reliable}.

One problem
we have encountered is that the test sentences from resource grammars are often
nonsensical semantically, and hence a native speaker might intuitively
say that a sentence is wrong, even though it is just unnatural. 
For instance, the function \t{AdvQVP} covers constructions such as ``you
did \emph{what}?''. However, the function itself is completely general
and can take any verb phrase and any question adverb, thus  bizarre
combinations like ``you saw the dog why'' may appear in the generated
test cases. For future work, we plan to use an external treebank to guide the algorithm to pick trees that also make sense semantically.

So far the only mode of operation is generating test cases for a
single function. 
% Generating test cases to all trees often leads to redundant
% trees---as we noted in Section~\ref{sec:wishlist_comments}, the trees
% that are needed to test \t{AdjCN} in Estonian are exactly the same
% trees we need to test \t{PrepNP}, even though the functions are
% seemingly separate. 
As future work, we are planning to add a separate
mode for testing the whole grammar from scratch: intentionally create
trees that test several functions at once.
We have an implementation only for \gf{} grammars so far, but the
general method works for any grammar formalism that can be compiled
into \pmcfg{}. \gf{} already supports reading context-free grammars,
so testing any existing \cfg{} is a matter of some preprocessing. 


% \todo{Other analyses: program analysis, compiler warnings,
%   possibilities in \gf{} that we cannot do in other programming
%   languages (I don't remember anymore what this is supposed to mean,
%   if you don't know either, just remove :-P)}





% include your own bib file like this:
\bibliographystyle{acl}
\bibliography{bibliography}

\end{document}
