%
% File coling2018.tex
%
% Contact: zhu2048@gmail.com & liuzy@tsinghua.edu.cn
%% Based on the style files for COLING-2016, which were, in turn,
%% Based on the style files for COLING-2014, which were, in turn,
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{coling2018}
\usepackage{times}
\usepackage{url}
\usepackage{color}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{stackengine}
\usepackage[normalem]{ulem}
\input{syntaxhilight} % suspicious

\def\t#1{\texttt{#1}}
\def\gf{\textsc{gf}}
\def\lfg{\textsc{lfg}}
\def\ccg{\textsc{ccg}}
\def\tag{\textsc{tag}}
\def\pmcfg{\textsc{pmcfg}}
\def\hpsg{\textsc{hpsg}}
\newcommand{\tts}[1]{{\tt #1}}
%\newcommand{\tts}[1]{{\tt \small #1}}
\newcommand{\todo}[1]{{\color{cyan}\textbf{[TODO: }#1\textbf{]}}}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Automatic systematic test case generation for producing reliable grammars}

\author{Inari Listenmaa and Koen Claessen \\
  Department of Computer Science and Engineering \\
  University of Gothenburg and Chalmers University of Technology \\
  Gothenburg, Sweden \\
  {\tt inari@chalmers.se, koen@chalmers.se} }
%\\\And
%  Koen Claessen \\
%  Department of Computer Science and Engineering \\
%  Chalmers University of Technology \\
%  Gothenburg, Sweden \\
 % {\tt koen@chalmers.se} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
We present a method for finding errors in formalized natural language grammars, by automatically and systematically generating test cases that are intended to be judged by a human oracle. The method works on a per-construction basis; given a construction from the grammar, it generates a finite but complete set of test sentences (typically tens or hundreds), where that construction is used in all possible ways. We contrast our method against using a corpus or a treebank, where no such completeness guarantees can be made. Our method is language-independent and is implemented for the grammar formalism PMCFG, but also works for weaker grammar formalisms.
\end{abstract}

\section{Introduction}

Grammar engineering has a lot in common with software
engineering. Analogous to a program specification, we use
descriptive grammar books; in place of unit tests, we have gold
standard corpora and test cases for manual inspection.
And just like any software, our grammars still contain bugs:
grammatical sentences that are rejected, ungrammatical
sentences that are parsed, or grammatical sentences that get the wrong
parse.

There are several ways to test grammars that do not involve human
labour. Morphology and lexicon can be compared against existing resources, or
if there are none, a large corpus of any text should give indications
whether the word forms are correct. The same corpus can be used to
test the coverage of the grammar: how many sentences are successfully parsed.
However, often we want information beyond numbers: do the rules we
wrote for relative clauses correctly accept all relative clauses and
nothing else? In other words, we are interested in the strong
generative capacity \cite{chomsky1963} of the grammar, i.e. combinations
of a string and its structural description.

Here is an example of a typical situation we want to improve. Suppose a
grammarian implements relative clauses, and then comes up with a test
suite of sentences with their analyses. The next grammarian implements
relative clauses for another language, and adapts the test set to the
new language. Every time someone touches relative clauses 
in any language, the test suite will be rerun and verified by
someone who knows the language, or compared to the original gold standard, 
if there is one. This scheme can fail for various reasons: 

% When implementing some feature, such as 
% relative clauses, the grammarian comes up with a test suite of 
% sentences that include relative clauses, and stores in the form of 
% abstract syntax trees. In principle, a test suite created for one 
% language can easily be reused for another, because the ASTs are 
% identical.

\begin{itemize}
\item The original list is not exhaustive: for instance, it tests only
``X, who loves me'' but not ``X, whom I love''. 
\item The original list is exhaustive in one language, but not in all:
for instance, it started in English and only included one noun, but in
French it would need at least one masculine and one feminine noun. 
\item The list is overly long, with redundant test cases, and human
testers are not motivated to read through. 
\item A grammarian makes a change somewhere else in the grammar, and
does not realise that it affects relative clauses, and thus does not
rerun the appropriate test suite. 
\end{itemize}

We present a method that addresses these problems, by designing a tool that can automatically generate test cases, given a grammar and a syntactic function that we want to test. Our tool improves on the four weak points in the following way:

\begin{itemize}
\item The set of test cases consists of the syntactic function, applied
  to all relevant arguments and the result is placed in all relevant
  contexts (``relevant'' is defined in
  Section~\ref{sec:details}).
  %Given a grammar and a category, the
  %program can extract all functions that produce or use the given category. 
\item The tests cases are automatically generated for each different
  language. If there is a parameter of gender or noun class in the
  grammar, then the program is guaranteed to choose an example of each
  of them, when it matters.
\item When some feature doesn't matter, the test cases are pruned: for
  example, in English we need to test a reflexive construct with three
  different 3rd person singular subjects, because the object has to
  agree with the subject: ``he sees himself'', ``she sees herself''
  and ``it sees itself''. With a non-reflexive object, it is
  enough to test with only one of \emph{he, she, it}, or any singular
  noun or proper name, because the agreement only shows in the verb
  form, thus generating both ``she sees a dog'' and ``John sees a
  dog'' is redundant.
\item The grammar is a collection of grammatical categories, syntactic
  functions and a lexicon, and everything is interconnected. By
  changing e.g. the category of prepositions, the changes are
  propagated to several functions, e.g. for building adjuncts (``in
  the house'') and complements (``believe in something''). This is
  all part of the grammar, and the chain of effects can be
  automatically traced. 
\end{itemize}

Our concrete implementation is for a particular grammar formalism, namely parallel multiple context-free grammars ({\sc pmcfg}) \cite{seki91pmcfg}, which is the core formalism used by the Grammatical Framework (\gf) \cite{ranta2004gf}. However, the method works for any formalism that is at most as expressive as PMCFG, including formalisms such as Tree-Adjoining Grammar (\tag) \cite{joshi1975tag} and Combinatorial Categorial Grammar (\ccg) \cite{steedman1988ccg}.

\section{Grammatical Framework} \label{sec:gf}
Grammatical Framework (\gf) \cite{ranta2004gf} 
is a framework for building multilingual grammar applications. Its main
components are a functional programming language for writing grammars
and a resource library \cite{ranta2009rgl}, which, as of March 2018,
contains the linguistic details of 40 natural languages. \gf{} has
been used in several projects \todo{Ask Aarne how to boast about \gf} and
is super cool.

A \gf{} grammar consists of an \emph{abstract syntax}, which is a set
of grammatical categories and functions between them, and one or more
\emph{concrete syntaxes}, which describe how the abstract functions
and categories are linearised, i.e. turned into surface strings. The
resulting grammar describes a mapping between concrete language
strings and their corresponding abstract trees. This mapping is
bidirectional---strings can be \emph{parsed} to trees, and trees
\emph{linearised} to strings. As an abstract syntax can have multiple
corresponding concrete syntaxes, the respective languages can be
automatically \emph{translated} from one to the other by first parsing
a string into a tree and then linearising the obtained tree into a new
string. 

% \todo{this is stolen from Janna's paper 2006--reformulate:}
% \begin{quote} { \em [RGL] Abstract syntax declares universal principles, while language-specific
% parameters are set in concrete syntax. We are not trying to answer the
% general question what constitutes universal grammar and what beyond
% universal grammar differentiates languages from one another. We look
% at GF parallel resource grammars as a way to simplify multilingual
% applications. \dots
% According to the ``division of labor'' principle, resource grammars
% comprise the necessary linguistic knowledge allowing application
% grammarians to concentrate on domain semantics.}
% \end{quote}



%Concrete problems: the kind of bugs we set out to find
%* Empty categories
%* Empty fields
%* Eliminated arguments

%Pick ~3 bugs: 
%what tree was generated? why? likelihood of finding this bug without our method.

%Results


\begin{figure}[h]
  \centering

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{abstract }\DataTypeTok{NounPhrases} \FunctionTok{=} \NormalTok{\{}
  \NormalTok{flags startcat }\FunctionTok{=} \DataTypeTok{NP} \NormalTok{;}
  \KeywordTok{cat}
    \DataTypeTok{NP} \NormalTok{; }\DataTypeTok{Adv} \NormalTok{;                   }\CommentTok{-- Non-terminal categories}
    \DataTypeTok{CN} \NormalTok{; }\DataTypeTok{Det} \NormalTok{; }\DataTypeTok{Adj} \NormalTok{; }\DataTypeTok{Prep} \NormalTok{;      }\CommentTok{-- Terminal (lexical) categories}
  \KeywordTok{fun}
    \NormalTok{DetNP} \FunctionTok{:} \DataTypeTok{Det} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;          }\CommentTok{-- e.g. "this"; "yours"}
    \NormalTok{DetCN} \FunctionTok{:} \DataTypeTok{Det} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{NP} \NormalTok{;    }\CommentTok{-- e.g. "this house"}
    \NormalTok{PrepNP} \FunctionTok{:} \DataTypeTok{Prep} \OtherTok{->} \DataTypeTok{NP} \OtherTok{->} \DataTypeTok{Adv} \NormalTok{; }\CommentTok{-- e.g. "without the house"}
    \NormalTok{AdjCN} \FunctionTok{:} \DataTypeTok{Adj} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;    }\CommentTok{-- e.g. "small house"}
    \NormalTok{AdvCN} \FunctionTok{:} \DataTypeTok{Adv} \OtherTok{->} \DataTypeTok{CN} \OtherTok{->} \DataTypeTok{CN} \NormalTok{;    }\CommentTok{-- e.g. "house on a hill"}

    \NormalTok{a, the, this, these, your }\FunctionTok{:} \DataTypeTok{Det} \NormalTok{;}
    \NormalTok{good, small, blue, ready }\FunctionTok{:} \DataTypeTok{Adj} \NormalTok{;}
    \NormalTok{house, hill }\FunctionTok{:} \DataTypeTok{CN} \NormalTok{;}
    \NormalTok{in, on, with, without }\FunctionTok{:} \DataTypeTok{Prep} \NormalTok{; }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

% \begin{verbatim}
% abstract NounPhrases = {
%   flags startcat = NP ;
%   cat
%     NP ; Adv ;                   -- Non-terminal categories
%     CN ; Det ; Adj ; Prep ;      -- Terminal (lexical) categories
%   fun
%     DetNP : Det -> NP ;          -- e.g. "this"; "yours"
%     DetCN : Det -> CN -> NP ;    -- e.g. "this house"
%     PrepNP : Prep -> NP -> Adv ; -- e.g. "without the house"
%     AdjCN : Adj -> CN -> CN ;    -- e.g. "small house"
%     AdvCN : Adv -> CN -> CN ;    -- e.g. "house on a hill"

%     a, the, this, these, your : Det ;
%     good, small, blue, ready : Adj ;
%     house, hill, cake : CN ;
%     in, on, with, without : Prep ; 
% }
% \end{verbatim}
  \caption{GF grammar for noun phrases}
\label{fig:exampleGrammar}
\end{figure}

Figure~\ref{fig:exampleGrammar} shows a small example of a GF abstract
grammar. The grammar generates noun phrases for a lexicon of 15
words (\emph{a, the, \dots, without}) in four lexical categories,
and five functions to construct phrases. \t{CN} stands for common
noun, and it can be modified by arbitrarily many adjectives (\t{Adj}),
e.g. \emph{small blue house} is an English linearisation of the
abstract syntax tree \t{AdjCN small (AdjCN blue house)}. A \t{CN} is
quantified into a noun phrase (\t{NP}) by adding a determiner
(\t{Det}), e.g. \emph{the small house} corresponds to tree \t{DetCN the (AdjCN small
  house)}. Alternatively, a \t{Det} can also become an independent
noun phrase (as in, \emph{(I like) this} instead of \emph{(I like) this
  house}) using the constructor \t{DetNP}. Finally, we can form an
adverb (\t{Adv}) by combining a preposition (\t{Prep}) with an \t{NP},
and those adverbs can modify yet another \t{CN}. 
We refer to this grammar throughout the paper.

As examples that help illustrate different testing needs for different languages, let us take three language-specific phenomena in the scope of our
small grammar: preposition contraction in Dutch, adjective agreement
in Estonian and determiner placement in Basque.

\subsection{Preposition contraction in Dutch} In Dutch, some prepositions should
merge with a single determiner or pronoun, e.g. \emph{met~dit} `with
this' becomes \emph{hiermee} `herewith', but stay independent when the
determiner quantifies a noun, e.g. \emph{met~dit~huis} `with this house'. 
Other prepositions, such as \emph{zonder} `without', do not
contract with any determiners: \emph{zonder~dit} `without this' and
\emph{zonder~dit~huis} `without this house'.
When testing \t{PrepNP}, we would like to see one preposition that
contracts and one that does not, as well as one \t{NP} that is a
single determiner, and one that comes from a noun. Since the result of
\t{PrepNP} is an adverb, which does not inflect any further, we are
happy with just finding the right arguments to \t{PrepNP}, no need for contexts.
In order to catch a bug in the function, or confirm there is none, we
need the following 4 trees: \\
\t{PrepNP} \{ \stackanchor{\tt with}{\tt without} \} 
           \{ \stackanchor{\tt DetNP this}{\tt DetCN this house} \}. 

\subsection{Adjective agreement in Estonian} In Estonian,
most adjectives agree with nouns in case and number in an attributive
position. However, participles are invariable (singular nominative) as 
attributes but inflect regularly in a predicative position, and a set
of invariable adjectives do not inflect in any position. Furthermore,
in 4 of the 14 grammatical cases, even the regular adjectives only
agree with the noun in number, but the case is always genitive.
The following table shows the different behaviours in attributive
position, with \emph{sinine} `blue' as an example of a regular
adjective, and \emph{valmis} `ready' as an invariable.

\begin{table}[h]
\small
\begin{tabular}{cllcllcll}
(1) & sinises & majas & (2) & sinise & majaga & (3) & valmis & majas \\
& blue-{\sc sg.ine} & house-{\sc sg.ine} &  & blue-{\sc sg.gen} & house-{\sc sg.com} &  & ready.{\sc sg.nom} & house-{\sc sg.ine} \\
& \multicolumn{2}{l}{`in a blue house'} &  & \multicolumn{2}{l}{`with a blue house'} &  & \multicolumn{2}{l}{`in a finished house'} \\
& sinistes & majades &  & siniste & majadega &  & valmis & majades \\
& blue-{\sc pl.ine} & house-{\sc pl.ine} &  & blue-{\sc pl.gen} & house-{\sc pl.com} &  & ready.{\sc sg.nom} & house-{\sc pl.ine} \\
& \multicolumn{2}{l}{`in blue houses'} &  & \multicolumn{2}{l}{`with blue
                                         houses'} &  &
                                                     \multicolumn{2}{l}{`in finished houses'}

\end{tabular}
\end{table}

% \begin{table}[h]
% \begin{tabular}{cllcll}
% (1) & suur-e        &  auto-ga       & (2) & suur-te  & auto-de-ga \\ 
%     & big-{\sc gen} &  car-{\sc com} &  & big-{\sc pl.gen} & car-{\sc pl-com} \\
%     & \multicolumn{2}{l}{`with (the) big cars'} 
%                                      &  & \multicolumn{2}{l}{`with (the) big cars'} \\
% \end{tabular}
% \end{table}

%\stackanchor{ \emph{suur-e} \emph{auto-ga}}{\small
%\emph{big}-\textsc{gen} \emph{car}-\textsc{com}} 

%\emph{suur-e} \emph{auto-ga}  \emph{big}-{\sc sg.gen} \emph{car}-\textsc{com} `with a big car'. 
% \noindent Thus in order to test adjectives as attributes, we need an
% example for one of the 10 ``usual'' cases and one of the 4 ``unusual''
% cases, one of each type of adjective, and one of each number. 
\noindent Since we are interested in adjectives, choosing \t{AdjCN} as
the base sounds reasonable---but that only creates an inflection
table, so we must think of a context too. Just like in English, number
comes from the determiner, so we need to wrap the CN in a \t{DetCN}
with two determiners of different number, for instance \t{this} and
\t{these}. But we still need an example for one of the 10 cases with
normal agreement, such as inessive (in something), and one of the 4
cases with restricted agreement, such as comitative (with something).
These cases correspond to the English prepositions \emph{in} and \emph{with},
so in this abstract syntax we can use \t{PrepNP} with the arguments
\t{in} and \t{with}. This is another showcase of the abstraction level
of GF: in the English concrete syntax, \t{Prep} contains a string
such as `in' or `with', and \t{PrepNP} concatenates the string from its
\t{Prep} argument into the resulting adverb, but in Estonian, \t{Prep}
contains a case, and \t{PrepNP} chooses that case from its \t{NP} argument.
The following set of 8 trees creates all the relevant
distinctions\footnote{If the grammar covered predicative
constructions, we would need a participle in the test set. As an
attribute, we do not need both participles and invariables,
because they behave identically, but as a predicative, regular and
participle adjectives behave the same, and differently from
invariable.}: 
 \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
             {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
             {\tt AdjCN}  \{\stackanchor{\tt blue}{\tt ready} \} 
             {\tt house)}.

% If we wanted to test \emph{adjectives} exhaustively, we would need one more context, where
% the adjective is in the predicative position: e.g. `the house is \verb|_|'.
% Furthermore, we need to add a participle to the test cases.
% As an attribute, we do not need both participles and invariables,
% because they behave identically, but as a predicative, regular and
% participle adjectives behave the same, and differently from
% invariable. If we want to test specifically adjectives and not
% \t{PrepNP}, we would prefer to see all types in all positions:
%  \t{PrepNP} \{ \stackanchor{\tt in}{\tt with} \}
%              {\tt (DetCN} \{ \stackanchor{\tt this}{\tt these} \} 
%              {\tt AdjCN}  \{\stackanchor{\tt blue}{\stackanchor{\tt
%                  ready}{\tt tired}} \} 
%              {\tt house)}.

\subsection{Determiner placement in Basque} In Basque, there are three
different ways to place a determiner into a noun phrase. When a number
(other than 1) or a possessive pronoun acts as a determiner in a
complex noun phrase, it is placed between ``heavy'' modifiers, such as
adverbials or relative clauses, and the rest of the noun
phrase. Demonstrative pronouns, such as \emph{this}, are placed after
all modifiers as an independent word. Number 1, which functions as an
indefinite article, acts like demonstratives, but the definite article
is a suffix. If there is a ``light'' modifier, such as an adjective,
the definite article attaches to the modifier; otherwise it attaches
to the noun. In order to test the implementation of this phenomenon,
we need the following 12 trees:  \\ 
\t{DetCN} \{
\stackanchor{\stackanchor{}{\tts{the}}}{\stackanchor{\tts{this}}{\tts{your}}}
\} \{ \stackanchor{\tt AdvCN on (DetCN the hill)}{$\varnothing$} \} 
\{ \stackanchor{\tt AdjCN small}{$\varnothing$} \}  {\tt house} 


\subsection{Using our tool} We have seen that, in order to test whether or not we have implemented a linguistic phenomenon correctly, we take a single function as a base, and describe all combinations arguments that are
needed to test the function. If the result of the function is an
inflection table rather than a fully specified result, then we need
several \emph{contexts} to squeeze out all the different forms.
For example, a \t{CN} in English is open for number---\t{house} is
really a table \{\t{Sg =>} \emph{``house''} \t{; Pl =>} \emph{``houses''}\}, and
applying a determiner chooses the right form: \t{DetCN this house}
linearises to \emph{this house} and \t{DetCN these house} linearises
to \emph{these houses}. 

\label{sec:wishlist_comments}
The grammar, with only 15-word lexicon and 5 syntactic functions,
generates over 10,000 %17,574
trees\footnote{e.g. {\tt DetCN the (AdvCN (PrepNP on
(DetCN a (AdjCN small hill)) (AdjCN blue house))} `the blue house on a
small hill'}  up to depth 5. 
However, as we have seen in the examples above, we can test complex morphosyntactic phenomena just with a set
of 4, 8 or 12 trees, depending on the complexity of the language.

As mentioned previously, the base of a test case is one syntactic
function, but often the same sentence ends up showcasing several
functions. In the Estonian example, we start from \t{AdjCN} 
and end up in a context formed by \t{PrepNP}---in fact, these 8 trees
are exactly the same that we would've chosen to test \t{PrepNP}. Thus,
it is possible to shrink the test cases effectively, if one wants to
test the whole grammar at one go.

Of course, such a test set will not catch e.g. individual
misspellings, or more systematic bugs in the morphological
paradigms. But there are easier methods to test for such bugs---our 
goal is to test the more abstract, syntactic phenomena with as few
trees as possible.  

\section{How the tool works}
\label{sec:details}

A GF grammar compiles into a low-level format called PGF (``Portable Grammar Format''), which is processed by our tool. For each category in the original grammar, the GF compiler introduces a new category in the PGF for each combination of parameters. For example for English adjectives, we get \texttt{A => A$_{pos}$, A$_{comp}$,
A$_{superl}$}, and for Spanish, \texttt{A => A$_{pos\times{}sg\times{}masc}$, \dots, A$_{superl\times{}pl\times{}fem}$}. 

This compilation step can dramatically increase the number of categories of the grammar, but it also removes the need for dealing with these parameters explicitly when we generate test cases. Instead, each syntactic function from the original grammar turns into multiple syntactic functions into the PGF -- one for each combination of parameters of its arguments.

We now describe the generation of test cases for a given syntactic function. We assume that all test cases are trees with the same start (top-level) category, such as \t{NP} in our example grammar, or \t{S} (for sentence) for more general grammars. The requirement is that the start category is linearized as one string only. (In a PMCFG, categories in general can be linearized to vectors of strings, which is perhaps unsuitable for test cases that are presented to a human.)

\paragraph{Enumerate functions} As we explained before, each syntactic function turns into multiple versions, one for each combination of parameters of its arguments. We test each of these versions seperately. This enumeration is the main reason we see several test cases in the examples in Section~\ref{sec:gf}.

In order to construct trees that use the syntactic function, we need to supply it with \emph{arguments}, as well as put the resulting tree into a \emph{context} that produces a tree of the correct start category.

\paragraph{Enumerate arguments} Some syntactic functions are simply a single lexical item (for example the word \emph{small}); in this case just the tree \t{small} is our answer. If we choose a function with arguments, such as for example \t{PrepNP}, then we have to supply it with argument trees. Each argument tree needs to be a tree belonging to the right category (in the example, \t{Prep} and \t{NP}, respectively).

When we test a function, we want to see whether or not it uses the right information from its arguments, in the right way. The information that a syntactic function uses is any of the strings that come from linearizing its arguments. In order to be able to see which string in the result comes from which string from which arguments, we want to generate test cases that only contain unique strings (no duplicates).

For example, when we test a preposition together with a noun, we want to pick a noun that actually has different forms (unique strings) for different prepositions, rather than having identical forms, because the human would not be able to see if the \t{PrepVP} function picked the wrong form.

It is often possible to generate one combination of arguments where all strings in the linearization are different. However, it is not always possible. This is why we in general aim to generate a set of arguments, where for each pair of strings from the arguments, there is always one test case where those strings are different. In this way, if the syntactic function contains a mistake, there is always one test case that reveals it.

\paragraph{Example: Test cases using \t{AdjCN}} Let us test the function
\t{AdjCN : Adj $\rightarrow$ CN $\rightarrow$ CN}, and take a Spanish
concrete syntax as an example. 
Firstly, we need a minimal and representative set of arguments of types
\t{Adj} and \t{CN}. Consider the nouns first: Spanish has a
grammatical gender, so in order to be representative, we need an
example of both masculine and feminine. Out of the small lexicon,
\t{house} (\emph{casa}) is feminine, and \t{hill} (\emph{cerro}) is
masculine, so we return those two nouns as the full set of argument
trees in \t{CN}. 

Secondly, we consider the adjectives. Most commonly, adjectives follow
the noun, e.g. \emph{casa peque\~{n}a} `small house', but some
adjectives precede the noun, e.g. \emph{buena casa} `good house'. Thus 
in order to cover the full spectrum of adjective placement, we need
one premodifier and one postmodifier adjective. We pick the words
\t{good} and \t{small} as the arguments of type \t{Adj}. 

Now, our full set of test cases are \t{AdjCN} applied to the cross
product of \{\stackanchor{\tt \small good}{\tt \small small}\}
$\times$ \{ \stackanchor{\tt \small house}{\tt \small hill}\}.
Note that \t{CN} is unspecified for number, because it is still waiting for a
determiner (e.g. \t{this} or \t{these}) to complete it into an
\t{NP}. Thus all the test cases contain both singular and plural
variants, and by linearising these 4 trees, we get the 8 strings shown
in Figure~\ref{fig:adjAttr}.

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
\centering
\begin{tabular}{| l | l |}
\hline
\t{AdjCN good house}   & \t{AdjCN good hill} \\ 
\textsc{(sg)} buena casa             & \textsc{(sg)} buen cerro \\
\textsc{(pl)} buenas casas           & \textsc{(pl)} buenos cerros \\ \hline

\t{AdjCN small house}   & \t{AdjCN small hill} \\ 
\textsc{(sg)} casa  peque\~{n}a            & \textsc{(sg)} cerro  peque\~{n}o \\
\textsc{(pl)} casas  peque\~{n}as          & \textsc{(pl)} cerros  peque\~{n}os \\ \hline
\end{tabular}
\caption{Agreement and placement of adjectives in attributive position}
\label{fig:adjAttr}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \todo{A picture of trees with holes}
 \caption{Trees with a hole of type \t{CN}}
\label{fig:treesWithHoles}
\end{minipage}
\end{figure}

\paragraph{Enumerate contexts} The third and last enumeration we perform when generating test cases is to generate all possible \emph{uses} of a function. After we provide a function with arguments, we need to put the result into a context, so that we can generate a single string from the result (a sentence). We do this for all trees we have generated so far.

The important thing here is that the generated set of contexts shows all the possible different ways the tree can be used. By \emph{context}, we mean a tree in
the start category, with a \emph{hole} of type \t{CN}, as shown in
Figure~\ref{fig:treesWithHoles}. A tree of type \t{CN} can be plugged into the hole to form a tree in the start category.

In this grammar, the only category above \t{CN} is \t{NP}, and there is only
one way that a \t{CN} can end up in an \t{NP}: by using the function
\t{DetCN : Det $\rightarrow$ CN $\rightarrow$ NP}. 

Let us return to our running example. So far the relevant features have
been grammatical gender an adjective placement---we have 4 trees with
all combinations of \{masculine, feminine\} and \{pre,post\}. The
resulting trees have \emph{variable} number, and we need to generate contexts that specify that number. In the PGF, the function \t{DetCN} actually comes in two versions: one for singular and one for plural determiners. Both of these use their arguments in different ways (different strings from the hole appear in the result). So, both versions of \t{DetCN} lead to one context each. The final contexts are \verb|DetCN this _| and  \verb|DetCN these _|. Note that we do not have to enumerate all possible first arguments to \t{DetCN}. We insert the 4 test
cases into the holes, and get 8 trees in total: \t{\{DetCN this (good
  house), \dots, DetCN these (small hill)\}}. 

\todo{a few lines on how to compute contexts}

\paragraph{Pruning} For the previous example, we did not need any pruning: the cross
product of all relevant distinctions produced a minimal and
representative set of trees. Now assume we have a larger grammar,
which also covers adjectives in a predicative position:
e.g. \emph{esta casa es peque\~{n}a} `this house is small' and
\emph{esta casa es buena} `this house is good'. The distinction which
made us choose \t{small} and \t{good} in the first place is now gone:
in predicative position, both adjectives behave the same. Thus, in
this larger grammar, when we want to test adjectives, it is necessary
to include two examples when in attributive position, but only one
when in predicative position. We describe exactly how this works in
Section~\ref{sec:details}. 
%In total we would get 12 sentences: the 8 shown previously, and 4 

\section{General features of \pmcfg: unused, equal,
  erased or empty fields}

\todo{rewrite/restructure/merge into something?}

Aside from concrete language-dependent phenomena, there are more
general, engineering questions a grammar writer may ask. For instance, say that our
concrete type for a \t{CN} in Dutch is an inflection table from case
to string, we would like to know if (a) a given string field is unreachable from the start category; (b) any two fields always contain the same string; or (c) some fields
are always the empty string. A yes answer to any of these may indicate a bug in the grammar.

In Dutch, nominative and accusative are only different for
pronouns, so for this grammar we would indeed find out that case is
redundant: all nominative and accusative fields would be
identical. As grammarians, we could decide to keep the distinction for
further extension of the grammar---maybe we want to add pronouns in
the future---or remove it as redundant.

\gf{} has the expressivity of \pmcfg{}, which means that it is
possible to erase arguments: say that there is a bug, \t{AdjCN : Adj
  $\rightarrow$ CN  $\rightarrow$ CN} never actually adds the
adjective to the new \t{CN}, in which case \t{AdjCN blue house} and
\t{house} are linearised identically. Instead of testing every single
function, we would like to know if there are any functions in the
grammar that behave like this.

The analyses mentioned in this section are implemented in a similar way to the method for enumerating all contexts.

\section{Use cases and evaluation}

Here is a typical use for the tool. 
Let us take the noun phrase grammar for Dutch, and pick a single function,
say \t{AdvCN}. We generate test cases, which include the following
trees: 
\begin{itemize}
\item \t{AdvCN (PrepNP next\_to (DetNP your)) hill} `hill next to
yours'
\item \t{AdvCN (PrepNP next\_to (DetNP your)) house} `house next
to yours'
\end{itemize}
In Dutch, the words \emph{hill} and \emph{house} have different
genders, and the word \emph{yours} has to agree in gender 
with the antecedent: \emph{(de) heuvel naast de jouwe} and \emph{(het)
  huis naast het jouwe}. The test cases reveal a bug, where \t{DetNP your} 
picks a gender too soon: always the neuter form, instead of leaving
gender open in an inflection table. We implement a fix by adding
gender as a parameter to the \t{Adv} type, and have \t{AdvCN} choose
the correct form based on the gender of the \t{CN}. 

After implementing the fix, we run a second test case generation: this
time, not meant for human eyes, but just to compare the old and new
versions of the grammar. We want to make sure that our changes 
%to \t{Adv}, \t{AdvCN} and \t{DetNP} 
have not caused new bugs in other functions. The simplest strategy is
to generate test cases for \emph{all} functions in both grammars, and
only show those outputs that differ between the grammars. After our
fixes, we get the following differences: 

\begin{itemize}
\item \t{DetCN the (AdvCN (PrepNP next\_to (DetNP your)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel naast {\bf  het} jouwe}}
   \item \emph{de heuvel naast {\bf  de} jouwe}
  \end{itemize}
\item \t{DetCN the (AdvCN (PrepNP without (DetNP this)) hill)}
  \begin{itemize}
   \item \emph{\sout{de heuvel zonder {\bf  dit}}}
   \item \emph{de heuvel zonder {\bf  deze}}
  \end{itemize}
\end{itemize}

\noindent We notice a side effect that we may not have thought of: the
gender is retained in all adverbs made of NPs made of determiners, so
now it has become impossible to say ``the hill without \emph{that}'' and
pointing to a house. So we do another round of modifications, compute
the difference (to the original grammar or to the intermediate), and
see if something else broke.

Note that generating test cases to all trees often leads to redundant
trees---as we noted in Section~\ref{sec:wishlist_comments}, the trees
that are needed to test \t{AdjCN} in Estonian are exactly the same
trees we need to test \t{PrepNP}, even though the functions are
seemingly separate. However, when our goal is just to compare the
strings and return the ones that differ, generating test cases for
each function is no problem. 
As future work, we are planning to add a separate mode for testing the
whole grammar from scratch: intentionally create trees that test
several functions at once.

% The tool is completely
% deterministic, that is, it chooses always the same subtree to
% represent a particular feature. On the one hand, this makes the task
% monotonous for the evaluator, but on the other hand, it makes it
% clearer to see the redundancy: if we have already shown a set of trees
% for \t{PrepNP}, we do not need to show them again for \t{AdjCN}.

\begin{table}[h]
\centering
\begin{tabular}{|lll|ll|ll|ll|}
\hline
\multicolumn{3}{|r}{Concrete grammar $\rightarrow$}              &
                                                                   \multicolumn{2}{|c}{\bf Dutch} & \multicolumn{2}{|c}{\bf Basque} & \multicolumn{2}{|c|}{\bf Estonian} \\
$\downarrow$ Abstract grammar & \#funs+lex & \#trees  &
                                                                 \#total & \#uniq & \#total & \#uniq  & \#total  & \#uniq \\ \hline
{\bf Noun phrases}     & 5+15          & \textgreater{}10,000          & 21    & 18     & 33      & 27      & 40       & 36     \\ \hline
{\bf Phrasebook}       & 130+160         & \textgreater{}480,000       & 2006  & 1892   & 2808    & 2650    & 1513     & 1314   \\ \hline
{\bf Resource grammar} & 217+446         & \textgreater{}500 billion   & 59,316 & 51,145  & 278,092  & 216,058  & 60,600    & 38,517   \\ \hline
\end{tabular}
\caption{Test cases for all functions in three grammars}
\label{results}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{|l|ll|ll|ll|}
\hline
{\bf Resource grammar function} &\multicolumn{2}{|c}{\bf Dutch} &
                                                                  \multicolumn{2}{|c}{\bf Basque} & \multicolumn{2}{|c|}{\bf Estonian} \\
                               &  \#trees & \#ctx &\#trees & \#ctx & \#trees & \#ctx  \\ \hline
\t{ComparA} `younger than me'  &  11      & 3     & 36     & 6     & 21      & 3   \\
% \t{FunRP~~} `mother of whom'  &  20      & 5     & 26     & 26    & 708     & 116 \\
\t{RelNP~~} `a cat that I saw' &  25      & 9     & 90     & 10    & 123     & 12 \\
 \t{ReflVP~} `see myself'      &  1655    & 23    & 10838  &  128  &1608     & 13   \\


\hline
\end{tabular}
\caption{Test cases for some individual functions in the resource grammar}
\label{results_indiv}
\end{table}

In order to evaluate our method, we generate test cases for grammars
of varying sizes, using the three languages presented earlier: Dutch,
Estonian and Basque. These languages come from different language
families, and cover a wide range of grammatical complexity. Dutch, an
Indo-European language, has fairly simple nominal and verbal
morphology, but the rules for handling word order, prefixes and
particles in verb phrases are somewhat intricate. Estonian and Basque
both have rich morphology, each featuring 14 nominal cases. However, Basque
verbs are significantly more complex---verbs agree with subject, object
and indirect object. This combined with all the tenses and moods, as
well as possible object cases, blows up the number of trees a
lot. Contrary to our expectations, we found Dutch and Estonian
behaving similarly to each other and Basque way out there, both in
execution time and examples generated.

Table~\ref{results} shows the number of generated trees for 
in total for all syntactic functions in the three grammars, and
Table~\ref{results_indiv} shows some example functions from the resource grammar. 
As stated earlier, we do not consider generating test cases for all
functions an optimal way of testing a whole resource grammar from scratch;
this gives merely a baseline reduction from all possible trees up to a
reasonable depth. We introduce the grammars and comment on the results
in the following sections. 

\subsection{Grammars}

The first grammar is the toy example introduced earlier in this
article: NounPhrases with 5 syntactic functions and 15 words in the
lexicon. We wrote the concrete syntaxes from scratch for each of the
languages, instead of using the full resource grammar and reducing it
to only noun phrases. All three concrete syntaxes were completed
in less than an hour, by an experienced grammarian with knowledge in
all three languages.

The second grammar is a mid-size application grammar: Phrasebook
\cite{ranta2010phrasebook}, with 42 categories such as \t{Person,
  Currency, Price} and \t{Nationality}, 160-word lexicon and 130
functions with arguments. As opposed to the trees that we have seen so far,
which only contain syntactic information, the trees in the Phrasebook
are much more semantic: for example, the abstract tree for the
sentence ``how far is the bar?'' in the Phrasebook is \t{PQuestion
  (HowFar (ThePlace Bar))}, in contrast to the resource grammar tree
{\tt \small UttQS (UseQCl (TTAnt TPres ASimul) PPos (QuestIComp
  (CompIAdv (AdvIAdv how\_IAdv (PositAdvAdj far\_A))) 
  (DetCN (DetQuant DefArt NumSg) (UseN bar\_N))))} for the same
sentence. Limiting up to depth 3, the Phrasebook grammar produces over
480,000 trees\footnote{Application grammars are usually
much more compact than resource grammars, hence depth 3 covers already
a lot of relevant trees.}. All three concrete syntaxes were
implemented using their respective resource grammars; thus if some
Phrasebook function has a bug, say it produces ``Spaniard restaurant''
instead of ``Spanish restaurant'', the problem could be in either grammar.
In the first case, the resource grammar contains both \t{spanish\_A} ``Spanish'' and
\t{spaniard\_N} ``Spaniard'', but the application grammarian has
chosen the wrong function.
In the second case, the application grammarian has correctly chosen
\t{spanish\_A} from the resource grammar, but that word itself is
linearised wrongly into ``Spaniard''.


% \footnote{For the resource grammar, depth
%   3 would be quite small and leave out many completely natural
%   phrases, but the abstract syntax of application grammars is often
%   much more compact.} 

The third grammar is a restricted version of the GF resource grammar,
with 84 categories, 217 syntactic functions and 446 words in the
lexicon. Since all the languages did not have a complete
implementation, we simply took the subset of functions that was
common, and removed manually a couple of rare constructions and words
that are potentially distracting. However, we should not limit the
lexicon too much, because we may miss important distinctions 
in some languages\footnote{To give a hypothetical example, some language may
have a bug that shows up only in animate nouns which end in a
consonant other than \emph{r}}. This subset of the resource grammar
produces hundreds of billions of trees up to depth 5.
%: say, animate and inanimate nouns, ending in front vowel and back vowel.

\subsection{Results}

\paragraph{Execution time} We ran all the experiments on a MacBook Air with 1,7 GHz processor and 8 GB RAM.
For the smaller grammars, all languages took just
seconds to run. For the resource grammar, Dutch and Estonian finished in
3--4 minutes,
% Several other languages, such as English, Swedish, \todo{Hindi,
% Bulgarian, ...} also needed only a few minutes. 
However, the Basque resource grammar is noticeably more complex, and
creating test trees for all functions took several hours. We ran the
experiment in smaller batches over two days, and noticed a lot of
variance: functions that handle e.g. noun phrases, adjectives and
adverbs ran in a few minutes, but a function involving verb phrases
could take an hour just by itself. 

\paragraph{Generated trees} 

We report two numbers: total number of trees, and unique trees. 


\paragraph{Finding bugs} 
We read through the test sentences of the small grammar in all the
three languages. 
For Dutch we had a native speaker; for Estonian a fluent non-native,
and for Basque, a beginner. None of the three grammars had been tested
systematically before---\cite{listenmaa_kaljurand2014} report testing
the morphological paradigms extensively against existing resources,
and for the syntactic functions, a test treebank of a few hundred trees.

%\todo{up to line 1977, 11 minutes, finish tomorrow}
%For the 1314 sentences in Estonian, it took \todo{n} minutes for a
%fluent non-native speaker to read through and mark suspicious-looking constructs

\subsection{State of the art}

Traditionally, GF grammars are tested by the grammarians themselves,
much in the way described in the introduction of this article. An example
human-written treebank can be found in \cite[p.~136--142]{khegai2006phd}.
For testing the coverage of the grammars, grammarians have used
treebanks such as the UD treebank \cite{nivre2016ud} and Penn treebank
\cite{marcus1993penntreebank}, and for testing morphology, various open-source resources
have been used, such as morphological lexica from the Apertium
project \cite{forcada2011apertium}.

%\todo{Pick one function, get a treebank, see how exhaustively the
%function is used in the treebank.}


\cite[pp.~212--213]{butt1999lfg} describes common methods of testing the
{\sc lfg} formalism: similarly to \gf, they use a combination of
human-written test suites meant to cover particular phenomena, and
external larger corpora to test the coverage. As a difference from \gf{}
testing tradition, their human-written test suites include also
ungrammatical sentences: those that the grammar should \emph{not} be
able to parse. However, their tests are only meant for monolingual
grammars, whereas \gf{} tests are for multilingual grammars, so they are
stored as trees. In other words, \gf{} tests only what the grammar
outputs, not what it parses.

Stephan Müller's sentence list testing only weak generative capacity,
this method is testing strong generative capacity




\section{Discussion}

We have only concentrated on GF grammars so far, but the method works
for any grammar formalism that can be compiled into parallel
multiple CFG (PMCFG) \cite{seki91pmcfg}. The expressive power of PMCFG lies
between mildly context-sensitive and context-sensitive, and thus any
grammar formalism that is less expressive can be expressed as a
PMCFG. This includes CFGs, and mildly context-sensitive formalisms
such as \tag{} \cite{joshi1975tag} and \ccg{} \cite{steedman1988ccg}. GF
already supports reading context-free grammars in labeled BNF format;
so testing any existing CFG is a matter of some pre-processing.

Some existing formalisms such as \hpsg{} and \lfg{} are fully
context-sensitive \todo{cite and find out if there's some subset with
  nice properties}.

\todo{Treebanks can complement the tree generation}

\todo{Other analyses: program analysis, compiler warnings,
  possibilities in GF and not programming languages}

Theoretical question: two grammars that produce the same language but
have different grammar rules.
NounPhrasesEus and NounPhrasesEusBind -- different number of concrete
categories, functions are grouped differently, and
representative+minimal test set is slightly different (smaller in the
one that uses BIND instead of full forms in inflection tables).

We believe this has both language typological and grammar engineering
implications---there is no way to implement Basque in a way that
results in as few example sentences as English, but other resource
grammarians have reported significant differences in complexity
between implementations---\todo{cite Ramona's Romanian RG} reports a
200-time reduction in the number of concrete rules after changing the
implementation of clitics in verb phrases.




% include your own bib file like this:
\bibliographystyle{acl}
\bibliography{bibliography}

\end{document}
